{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9V1iTNABxI0I"
   },
   "source": [
    "# Homework 2: Prompting & Generation with LMs (50 points)\n",
    "\n",
    "The second homework zooms in on the following skills: on gaining a deeper understanding of different state-of-the-art prompting techniques and training your critical conceptual thinking regarding research on LMs.\n",
    "\n",
    "### Logistics\n",
    "\n",
    "* submission deadline: June 2nd th 23:59 German time via Moodle\n",
    "  * please upload a **SINGLE .IPYNB FILE named Surname_FirstName_HW2.ipynb** containing your solutions of the homework.\n",
    "* please solve and submit the homework **individually**!\n",
    "* if you use Colab, to speed up the execution of the code on Colab, you can use the available GPU (if Colab resources allow). For that, before executing your code, navigate to Runtime > Change runtime type > GPU > Save.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ns54D_OBxI0J"
   },
   "source": [
    "## Exercise 1: Advanced prompting strategies (16 points)\n",
    "\n",
    "The lecture discussed various sophisticated ways of prompting language models for generating texts. Please answer the following questions about prompting techniques in context of different models, and write down your answers, briefly explaining them (max. 3 sentences). Feel free to actually implement some of the prompting strategies to play around with them and build your intuitions.\n",
    "\n",
    "> Consider the following language models:\n",
    "> * GPT-2, GPT-4, Vicuna (an instruction-tuned version of Llama) and Llama-2-7b-base.\n",
    ">  \n",
    "> Consider the following prompting / generation strategies:\n",
    "> * beam search, tree-of-thought reasoning, zero-shot CoT prompting, few-shot CoT prompting, few-shot prompting.\n",
    ">\n",
    "> For each model, which strategies do you think work well, and why? Do you think there are particular tasks or contexts, in which they work better, than in others?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## GPT-2\n",
    "GPT2 is a relatively smaller (only 124M params) base causal language model, i.e., it is more geared towards language generation rather than instruction-following or reasoning. In my experience, GPT2 does not work well with any of the zero shot or few shot prompting strategies (such as `Sentence1: ... Sentiment: ...` type prompts) and instead of generating correct labels, it extends the given prompt by generating new such (sentence, sentiment) pairs. However, if the few shot prompt is phrased as a natural language completion task, like (`Consider this sentence \"...\", this has positive sentiment.`), GPT2 is often able to complete the prompt as described in the examples but mostly it is wrong.\n",
    "\n",
    "Since GPT2 is a causal language model, decoding strategies that help generate coherent and fluent text, such as beam search works better than pure sampling or greedy decoding. It might work well for text completion tasks such as it can complete writing an email given the beginning, but it struggles to follow instructions and tasks having complex reasoning.\n",
    "\n",
    "---\n",
    "\n",
    "## GPT-4\n",
    "\n",
    "GPT-4 is a larger and more advanced model than GPT-2, and is more of an assistant than a pure language model. It works well with almost all the prompting strategies as most likely it has seen instances of such instruction data during training/instruction tuning. It also has the ability to read from large pdf files/research papers and summarize them, generate coherent code with minimal instructions etc.  \n",
    "\n",
    "GPT-4 also excels in tasks that require complex reasoning, such as solving math problems, generating explanations, or answering multi-step questions.\n",
    "\n",
    "---\n",
    "\n",
    "## Vicuna\n",
    "\n",
    "Vicuna is a chat assistant trained by fine-tuning Llama 2 on user-shared conversations, so it can be naturally expected to follow instructions type prompts like zero shot and few shot (even without phrased as a completion task). I also prompted `Vicuna v1.5 (13B)` with the reasoning task given in slides:\n",
    "```\n",
    "Do the numbers of letters in all words starting with a vowel from the following list sum up to 42?\n",
    "Polina, Michael, eggplant, cheese, oyster, imagination, elucidation, induce\n",
    "\n",
    "Let's think step by step. Correctness is very important here.\n",
    "```\n",
    "and it generated the following:\n",
    "```\n",
    "Let's count the number of letters in each word starting with a vowel:\n",
    "Polina - 5 letters\n",
    "Michael - 6 letters\n",
    "eggplant - 8 letters\n",
    "cheese - 5 letters\n",
    "oyster - 6 letters\n",
    "imagination - 11 letters\n",
    "elucidation - 12 letters\n",
    "induce - 5 letters\n",
    "\n",
    "Adding up the number of letters in all the words starting with a vowel:\n",
    "5 + 6 + 8 + 5 + 6 + 11 + 12 + 5 = 57\n",
    "The sum of letters in all words starting with a vowel is 57, not 42. Therefore, the answer is no, the numbers of letters in all words starting with a vowel from the given list do not sum up to 42.\n",
    "```\n",
    "which albeit incorrect, demonstrates its ability to reason through a logical problem. So Vicuna is suitable for a variety of tasks that require instruction following, code generation etc.\n",
    "\n",
    "---\n",
    "\n",
    "## Llama-2-7b-base\n",
    "\n",
    "Llama-2-7b-base is again a pretrained causal language model and it is a larger model than GPT-2. Since it is not instruction tuned, it may have a hard time following zero shot or few shot prompts.\n",
    "\n",
    "When few shot prompted with NLI task (`Sentence 1: ... Sentence 2: ... Label: `), instead of generating the label, it generated many more such examples just as same as GPT2. It also could not perform the logical reasoning task and generated the following:\n",
    "```\n",
    "Does the number of letters in all words starting with a vowel from the following list sum up to 42?\n",
    "(The words are Polina, Michael, eggplant, cheese, oyster, imagination, elucidation, induce)\n",
    "Yes, it does. (3 votes)\n",
    "No, it doesn't. (1 vote)\n",
    "I don't know. (1 vote)\n",
    "Yes, it does. (1 vote)\n",
    "No, it doesn't. (1 vote)\n",
    "I don't know. (0 votes)\n",
    "Re: A riddle\n",
    "Post by jerry » Tue Jul 16, 2019 12:07 pm\n",
    "The answer is \"yes\".\n",
    "Post by A.J. » Tue Jul 16, 2019 12:10 pm\n",
    "I'm not sure if this is a riddle or not.\n",
    "Post by jerry » Tue Jul 16, 2019 1:15 pm\n",
    "It is a riddle.\n",
    "Post by A.J. » Tue Jul 16, 2019 1:20 pm\n",
    "Post by jerry » Tue Jul 16, 2019 10:16 pm\n",
    "Post by A.J. » Wed Jul 17, 2019 9:27 am\n",
    "Post by jerry » Wed Jul 17, 2019 10:24 am\n",
    "Post by A.J. » Wed Jul 17, 2019 11:26 am\n",
    "Post by jerry » Wed Jul 17, 2019 12:23 pm\n",
    "Post by A.J. » Wed Jul 17, 2019 12:28 pm\n",
    "Post by jerry » Wed Jul 17, 2019 1:24 pm\n",
    "Post by A.J. » Wed Jul 17, 2019 1:34 pm\n",
    "Post by jerry » Wed Jul 17, 2019 10:07 pm\n",
    "Post by A.J. » Thu Jul 18, 2019 9:16\n",
    "```\n",
    "which looks like a post with some voting options and it might have come from the training data.\n",
    "\n",
    "So Llama-2-7b-base might perform well in tasks that require generating text based on prompts, such as writing articles or completing chatbot responses.\n",
    "\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ku33qTdVxI0K"
   },
   "source": [
    "## Exercise 2: Prompting for NLI & Multiple-choice QA (14 points)\n",
    "\n",
    "In this exercise, you can let your creativity flow -- your task is to come up with prompts for language models such that they achieve maximal accuracy on the following example tasks. Feel free to take inspiration from the in-class examples of the sentiment classification task. Also feel free to play around with the decoding scheme and see how it interacts with the different prompts.\n",
    "\n",
    "**TASK:**\n",
    "> Use the code that was introduced in the Intro to HF sheet to load the model and generate predictions from it with your sample prompts.\n",
    ">\n",
    "> * Please provide your code.\n",
    "\n",
    "The code is provided in the following cells.\n",
    "\n",
    "---\n",
    "\n",
    "> * Please report the **best prompt** that you found for each model and task (i.e., **NLI** and **multiple choice QA**), and the decoding scheme parameters that you used.\n",
    "\n",
    "## For the NLI task\n",
    "I have used a few shot prompt that gives the task description at first, and also adds `Let's think step by step` to nudge the model to reason logically. One example full prompt is given below.\n",
    "```\n",
    "I will give you two sentences, you need to tell me which category the pair of sentences belong to.\n",
    "There are three categories: \"Contradiction\", \"Neutral\" and \"Entailment\".\n",
    "If the second sentence contradicts in any way to the first sentence, you would say it is \"Contradiction\".\n",
    "If no conclusion can be drawn, or the second sentence need not necessarily follow from the first one, or contradict the first one, you would say it is \"Neutral\".\n",
    "If the second sentence logically follows from the first sentence, you would say it is \"Entailment\".\n",
    "Also study the examples below.\n",
    "Consider the two sentences: \"A man, woman, and child enjoying themselves on a beach.\" and\n",
    "\"A family of three is at the mall shopping.\". Let's think step by step. The family cannot be at the beach and at the mall at the same time, so the second sentence contradicts the first one and does not follow from the first one, and it is an example of \"Contradiction\" category.\n",
    "\n",
    "Consider the two sentences: \"A woman wearing all white and eating, walks next to a man holding a briefcase.\" and\n",
    "\"A married couple is walking next to each other.\". Let's think step by step. The man and woman walking next to each other on road need not be related to each other, so the second sentence neither contradicts nor follows from the first one, and it is an example of \"Neutral\" category.\n",
    "\n",
    "Consider the two sentences: \"People waiting to get on a train or just getting off.\" and\n",
    "\"There are people just getting on a train.\". Let's think step by step. As some people were waiting to get on the train, they would definitely get on the train, so the second sentence does not contradict the first one and it logically follows from the first one, and it is an example of \"Entailment\" category.\n",
    "\n",
    "Consider the two sentences: \"A person on a horse jumps over a broken down airplane.\" and\n",
    "\"A person is training his horse for a competition.\". Let's think step by step.\n",
    "```\n",
    "\n",
    "I have used sampling based decoding `do_sample=True` with `temperature=0.4`, and `max_new_tokens=75` since the model was also required to output its reasoning.\n",
    "\n",
    "\n",
    "\n",
    "## For the QA task\n",
    "I again found few shot prompting with task description (`Please answer the following question`) to work reasonably well. One full example is given below.\n",
    "```\n",
    "Please answer the following question: What is a great place to lay in the sun? Choose one of these four options: in the basement, west, solar system, beach, beans. The correct answer is: beach.\n",
    "\n",
    "Please answer the following question: What might be the result of a season of successful skiing? Choose one of these four options: finish line, broken bones, broken legs, chapped lips, healthy body. The correct answer is: healthy body.\n",
    "\n",
    "Please answer the following question: She loved buying products, she was driven by her what to shop more than any practical needs? Choose one of these four options: desire, money, time, credit, spending money. The correct answer is: desire.\n",
    "\n",
    "Please answer the following question: What might you feel after doing housework for hours? Choose one of these four options: anger, not boredom, stress, boredom, anxiety. The correct answer is: stress.\n",
    "\n",
    "Please answer the following question: The president is the leader of what institution? Choose one of these four options: walmart, white house, country, corporation, government. The correct answer is:\n",
    "```\n",
    "\n",
    "The decoding parameters did not seem to have much impact on this, and I used sampling based decoding (same as NLI task) but with `max_new_tokens=10` since now the model only needs to generate few tokens to copy the correct answer from the given choices.\n",
    "\n",
    "---\n",
    "> * Please write a brief summary of your explorations, stating what you tried, what worked (better), why you think that is.\n",
    "\n",
    "## NLI task\n",
    "As mentioned earlier, I found the few shot cot type prompt with task description and clearly stating that there are 3 categories to be better than other prompts for both the models. \n",
    "\n",
    "In my experiments (not included in this notebook for compactness), I observed that the few shot prompt of the style `Sentence 1: ... Sentence 2: ... Label: ...` does not work, and the model instead of generating the correct label, leaves it blank and starts to generate new questions/sentence pairs. This is likely because **Pythia was not instruction tuned**, so it cannot be expected to perform as good as chat assistants like ChatGPT and others, and expects the task to be phrased as a **text completion** problem.\n",
    "\n",
    "I also observed that when the 3 categories were not explicitly stated, the model often invents new categories (such as `Disagreement`, `Disjunction`). This effect was more pronounced with high temperature (`0.9`).\n",
    "\n",
    "Decoding schemes seem to have not much effect on the generated response, all seemed equally bad or good for this task.\n",
    "\n",
    "\n",
    "## QA task\n",
    "\n",
    "I observed similar non-compliant behaviour when prompted with zero-shot prompts for the QA task, one example being:\n",
    "```\n",
    "Please answer the following question: The only baggage the woman checked was a drawstring bag, where was she heading with it? Choose one of these four options: garbage can, military, jewelry store, safe, airport. The correct answer is: the baggage was checked out.\n",
    "\n",
    "The only baggage the woman checked was\n",
    "```\n",
    "so the model did not answer the question correctly, and it instead started to generate a continuation. But with the few shot examples, the models generated one of the choices as the output.\n",
    "\n",
    "Again decoding schemes here seem to have minor effect.\n",
    "\n",
    "---\n",
    "\n",
    "* Models: Pythia-410m, Pythia-1.4b\n",
    "* Tasks: please **test** the model on the following sentences and report the accuracy of the model with your best prompt and decoding configurations.\n",
    "  * Natural language inference: the task is to classify whether two sentences form a **\"contradiction\"** or an **\"entailment\"**, or the relation is **\"neutral\"**. The gold labels are provided for reference here, but obviously shouldn't be given to the model at test time.\n",
    "    * A person on a horse jumps over a broken down airplane. A person is training his horse for a competition. neutral\n",
    "    * A person on a horse jumps over a broken down airplane. A person is outdoors, on a horse. entailment\n",
    "    * Children smiling and waving at camera. There are children present. entailment\n",
    "    * A boy is jumping on skateboard in the middle of a red bridge. The boy skates down the sidewalk. contradiction\n",
    "    * An older man sits with his orange juice at a small table in a coffee shop while employees in bright colored shirts smile in the background. An older man drinks his juice as he waits for his daughter to get off work. neutral\n",
    "    * High fashion ladies wait outside a tram beside a crowd of people in the city. The women do not care what clothes they wear. contradiction\n",
    "  * Multiple choice QA: the task is to predict the correct answer option for the question, given the question and the options (like in the task of Ex. 3 of homework 1). The gold labels are provided for reference here, but obviously shouldn't be given to the model at test time.\n",
    "    * The only baggage the woman checked was a drawstring bag, where was she heading with it? [\"garbage can\", \"military\", \"jewelry store\", \"safe\", \"airport\"] -- airport\n",
    "    * To prevent any glare during the big football game he made sure to clean the dust of his what? [\"television\", \"attic\", \"corner\", \"they cannot clean corner and library during football match they cannot need that\", \"ground\"] -- television\n",
    "    * The president is the leader of what institution? [\"walmart\", \"white house\", \"country\", \"corporation\", \"government\"] -- country\n",
    "    * What kind of driving leads to accidents? [\"stressful\", \"dangerous\", \"fun\", \"illegal\", \"deadly\"] -- dangerous\n",
    "    * Can you name a good reason for attending school? [\"get smart\", \"boredom\", \"colds and flu\", \"taking tests\", \"spend time\"] -- \"get smart\"\n",
    "    * Stanley had a dream that was very vivid and scary. He had trouble telling it from what? [\"imagination\", \"reality\", \"dreamworker\", \"nightmare\", \"awake\"] -- reality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "9u5JHI22xMKv"
   },
   "outputs": [],
   "source": [
    "# install utilities in colab\n",
    "# !pip install accelerate\n",
    "# !pip install transformers\n",
    "# !pip install datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "RpU9K5dUyMyO",
    "outputId": "a121b2f3-f830-48a5-cfd8-0c357fba4ada"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cuda\n"
     ]
    }
   ],
   "source": [
    "# import relevant packages\n",
    "import torch\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "\n",
    "# define computational device\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "    print(f\"Device: {device}\")\n",
    "elif torch.backends.mps.is_available():\n",
    "    device = torch.device(\"mps\")\n",
    "    print(f\"Device: {device}\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "    print(f\"Device: {device}\")\n",
    "\n",
    "# convenience function for nicer output\n",
    "def pretty_print(s):\n",
    "    print(\"Pretty printed output:\\n\" + 100 * '-')\n",
    "    print(tokenizer.decode(s, skip_special_tokens=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cQl_EMKGjcmD"
   },
   "source": [
    "## Some data preprocessing steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "TXH6l4aNyYCI",
    "outputId": "47d15b98-25d7-4ba7-8fef-e755dd0d2116"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('A person on a horse jumps over a broken down airplane.', 'A person is training his horse for a competition.', 'neutral')\n",
      "('The only baggage the woman checked was a drawstring bag, where was she heading with it?', '[\"garbage can\", \"military\", \"jewelry store\", \"safe\", \"airport\"]', 'airport')\n"
     ]
    }
   ],
   "source": [
    "data1 = \"\"\"A person on a horse jumps over a broken down airplane. A person is training his horse for a competition. neutral\n",
    "A person on a horse jumps over a broken down airplane. A person is outdoors, on a horse. entailment\n",
    "Children smiling and waving at camera. There are children present. entailment\n",
    "A boy is jumping on skateboard in the middle of a red bridge. The boy skates down the sidewalk. contradiction\n",
    "An older man sits with his orange juice at a small table in a coffee shop while employees in bright colored shirts smile in the background. An older man drinks his juice as he waits for his daughter to get off work. neutral\n",
    "High fashion ladies wait outside a tram beside a crowd of people in the city. The women do not care what clothes they wear. contradiction\"\"\"\n",
    "\n",
    "dataset = [] # list (sentence1, sentence2, label) tuples\n",
    "for line in data1.split(\"\\n\"):\n",
    "    # print(line)\n",
    "    dataset.append((line.split('.')[0].strip()+'.', line.split('.')[1].strip()+'.', line.split('.')[2].strip()))\n",
    "print(dataset[0])\n",
    "\n",
    "data2 = \"\"\"The only baggage the woman checked was a drawstring bag, where was she heading with it? [\"garbage can\", \"military\", \"jewelry store\", \"safe\", \"airport\"] -- airport\n",
    "To prevent any glare during the big football game he made sure to clean the dust of his what? [\"television\", \"attic\", \"corner\", \"they cannot clean corner and library during football match they cannot need that\", \"ground\"] -- television\n",
    "The president is the leader of what institution? [\"walmart\", \"white house\", \"country\", \"corporation\", \"government\"] -- country\n",
    "What kind of driving leads to accidents? [\"stressful\", \"dangerous\", \"fun\", \"illegal\", \"deadly\"] -- dangerous\n",
    "Can you name a good reason for attending school? [\"get smart\", \"boredom\", \"colds and flu\", \"taking tests\", \"spend time\"] -- \"get smart\"\n",
    "Stanley had a dream that was very vivid and scary. He had trouble telling it from what? [\"imagination\", \"reality\", \"dreamworker\", \"nightmare\", \"awake\"] -- reality\"\"\"\n",
    "\n",
    "dataset2 = [] # (question, (answer choices tuple), correct choice)\n",
    "for line in data2.split('\\n'):\n",
    "    question, choices_and_answer = line.split(\"?\")\n",
    "    dataset2.append(\n",
    "        (\n",
    "            question.strip() + \"?\",\n",
    "            choices_and_answer.strip().split(\"--\")[0].strip(),\n",
    "            choices_and_answer.strip().split(\"--\")[1].strip(),\n",
    "        )\n",
    "    )\n",
    "print(dataset2[0])\n",
    "\n",
    "## some utility to see model sizes\n",
    "def get_num_parameters(model: torch.nn.Module, count_nonzero_only=False) -> int:\n",
    "    \"\"\"\n",
    "    calculate the total number of parameters of model\n",
    "    :param count_nonzero_only: only count nonzero weights\n",
    "    \"\"\"\n",
    "    num_counted_elements = 0\n",
    "    for param in model.parameters():\n",
    "        if count_nonzero_only:\n",
    "            num_counted_elements += param.count_nonzero()\n",
    "        else:\n",
    "            num_counted_elements += param.numel()\n",
    "    return num_counted_elements\n",
    "\n",
    "\n",
    "def get_model_size(model: torch.nn.Module, data_width=32, count_nonzero_only=False) -> int:\n",
    "    \"\"\"\n",
    "    calculate the model size in bits\n",
    "    :param data_width: #bits per element\n",
    "    :param count_nonzero_only: only count nonzero weights\n",
    "    \"\"\"\n",
    "    return get_num_parameters(model, count_nonzero_only) * data_width\n",
    "\n",
    "Byte = 8\n",
    "KiB = 1024 * Byte\n",
    "MiB = 1024 * KiB\n",
    "GiB = 1024 * MiB"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bGtqyA-SlBY1"
   },
   "source": [
    "## Prompt preparatory code for the NLI task\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "3tmJnMyplAx1"
   },
   "outputs": [],
   "source": [
    "single_inv = \"'\"\n",
    "def prompt5_few_shot_cot(sentence1, sentence2):\n",
    "    # examples taken from https://huggingface.co/datasets/stanfordnlp/snli\n",
    "    few_shot_prompt=\"\"\"Consider the two sentences: \"A man, woman, and child enjoying themselves on a beach.\" and\n",
    "\"A family of three is at the mall shopping.\". Let's think step by step. The family cannot be at the beach and at the mall at the same time, so the second sentence contradicts the first one and does not follow from the first one, and it is an example of \"Contradiction\" category.\n",
    "\n",
    "Consider the two sentences: \"A woman wearing all white and eating, walks next to a man holding a briefcase.\" and\n",
    "\"A married couple is walking next to each other.\". Let's think step by step. The man and woman walking next to each other on road need not be related to each other, so the second sentence neither contradicts nor follows from the first one, and it is an example of \"Neutral\" category.\n",
    "\n",
    "Consider the two sentences: \"People waiting to get on a train or just getting off.\" and\n",
    "\"There are people just getting on a train.\". Let's think step by step. As some people were waiting to get on the train, they would definitely get on the train, so the second sentence does not contradict the first one and it logically follows from the first one, and it is an example of \"Entailment\" category.\"\"\"\n",
    "    prompt = f'\\n\\nConsider the two sentences: \"{sentence1}\" and\\n\"{sentence2}\". Let{single_inv}s think step by step.'\n",
    "    return few_shot_prompt + prompt\n",
    "\n",
    "\n",
    "def prompt5_few_shot_cot_with_rules(sentence1, sentence2):\n",
    "    # examples taken from https://huggingface.co/datasets/stanfordnlp/snli\n",
    "    rules=\"\"\"I will give you two sentences, you need to tell me which category the pair of sentences belong to.\n",
    "There are three categories: \"Contradiction\", \"Neutral\" and \"Entailment\".\n",
    "If the second sentence contradicts in any way to the first sentence, you would say it is \"Contradiction\".\n",
    "If no conclusion can be drawn, or the second sentence need not necessarily follow from the first one, or contradict the first one, you would say it is \"Neutral\".\n",
    "If the second sentence logically follows from the first sentence, you would say it is \"Entailment\".\n",
    "Also study the examples below.\\n\"\"\"\n",
    "    few_shot_prompt=\"\"\"Consider the two sentences: \"A man, woman, and child enjoying themselves on a beach.\" and\n",
    "\"A family of three is at the mall shopping.\". Let's think step by step. The family cannot be at the beach and at the mall at the same time, so the second sentence contradicts the first one and does not follow from the first one, and it is an example of \"Contradiction\" category.\n",
    "\n",
    "Consider the two sentences: \"A woman wearing all white and eating, walks next to a man holding a briefcase.\" and\n",
    "\"A married couple is walking next to each other.\". Let's think step by step. The man and woman walking next to each other on road need not be related to each other, so the second sentence neither contradicts nor follows from the first one, and it is an example of \"Neutral\" category.\n",
    "\n",
    "Consider the two sentences: \"People waiting to get on a train or just getting off.\" and\n",
    "\"There are people just getting on a train.\". Let's think step by step. As some people were waiting to get on the train, they would definitely get on the train, so the second sentence does not contradict the first one and it logically follows from the first one, and it is an example of \"Entailment\" category.\"\"\"\n",
    "    prompt = f'\\n\\nConsider the two sentences: \"{sentence1}\" and\\n\"{sentence2}\". Let{single_inv}s think step by step.'\n",
    "    return rules + few_shot_prompt + prompt\n",
    "\n",
    "def prepare_input(premise, hypothesis, prompt_function):\n",
    "    prompt = prompt_function(premise, hypothesis)\n",
    "    input_ids = tokenizer(prompt, return_tensors=\"pt\").input_ids.to(device)\n",
    "    return input_ids"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ha9NL0cWk39P"
   },
   "source": [
    "## Prompt preparatory code for the QA task\n",
    "\n",
    "For the question answer again I found giving few examples are helpful to the model. I copied the below 4 examples from the commonsenseqa dataset to generate the fewshot prompt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "Ydm3dLRwkljg"
   },
   "outputs": [],
   "source": [
    "# some few shot examples for QA task\n",
    "few_shot_examples = [\n",
    "    (\n",
    "        'What is a great place to lay in the sun?',\n",
    "        '[\"in the basement\", \"west\", \"solar system\", \"beach\", \"beans\"]',\n",
    "        'beach'\n",
    "    ),\n",
    "    (\n",
    "        'What might be the result of a season of successful skiing?',\n",
    "        '[\"finish line\", \"broken bones\", \"broken legs\", \"chapped lips\", \"healthy body\"]',\n",
    "        \"healthy body\"\n",
    "    ),\n",
    "    (\n",
    "        'She loved buying products, she was driven by her what to shop more than any practical needs?',\n",
    "        '[\"desire\", \"money\", \"time\", \"credit\", \"spending money\"]',\n",
    "        'desire'\n",
    "    ),\n",
    "\n",
    "    (\n",
    "        'What might you feel after doing housework for hours?',\n",
    "        '[\"anger\", \"not boredom\", \"stress\", \"boredom\", \"anxiety\"]',\n",
    "        'stress'\n",
    "    )\n",
    "]\n",
    "\n",
    "\n",
    "def qa_prompt_with_task_description(question, choices):\n",
    "    # options = ['A', 'B', 'C', 'D']\n",
    "    # choices = list(zip(options, eval(choices)))\n",
    "    # prompt = f\"Please answer the following question: {question} Choose one of these four options: {' '.join(['. '.join(x) for x in choices])}. The correct answer is:\"\n",
    "    prompt = f\"Please answer the following question: {question} Choose one of these four options: {', '.join( eval(choices))}. The correct answer is:\"\n",
    "    return prompt\n",
    "\n",
    "def qa_prompt_few_shot(question, choices):\n",
    "    fewshotprompt = \"\"\n",
    "    for (q, c, a) in few_shot_examples:\n",
    "        fewshotprompt += f\"Please answer the following question: {q} Choose one of these four options: {', '.join(eval(c))}. The correct answer is: {a}.\\n\\n\"\n",
    "\n",
    "    return fewshotprompt + qa_prompt_with_task_description(question, choices)\n",
    "\n",
    "def prepare_input_for_qa_task(question, choices, prompt_function):\n",
    "    prompt = prompt_function(question, choices)\n",
    "    input_ids = tokenizer(prompt, return_tensors=\"pt\").input_ids.to(device)\n",
    "    return input_ids"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Z28BwKTCyc_u"
   },
   "source": [
    "# Pythia-410M model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "diW8dKCsxMTh",
    "outputId": "6483659e-2b4d-4d4f-f1a1-236cf954497d"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:89: UserWarning: \n",
      "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
      "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
      "You will be able to reuse this secret in all of your notebooks.\n",
      "Please note that authentication is recommended but still optional to access public models or datasets.\n",
      "  warnings.warn(\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"EleutherAI/Pythia-410m\")\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    \"EleutherAI/Pythia-410m\",\n",
    "    # trust_remote_code=True,\n",
    "    # torch_dtype=torch.float16,\n",
    ").to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "h6UoX1tTjn7T"
   },
   "source": [
    "## Pythia-410M on NLI task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "IHqnSd6cneU9",
    "outputId": "7bb22372-51f6-49a0-c9dd-4c23de6b8428"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NLI Task\n",
      "model has #params = 405.33 M\n",
      "model has size = 1546.23 MiB = 1.51 GiB\n",
      "generating for i: 1/6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pretty printed output:\n",
      "----------------------------------------------------------------------------------------------------\n",
      "I will give you two sentences, you need to tell me which category the pair of sentences belong to.\n",
      "There are three categories: \"Contradiction\", \"Neutral\" and \"Entailment\".\n",
      "If the second sentence contradicts in any way to the first sentence, you would say it is \"Contradiction\".\n",
      "If no conclusion can be drawn, or the second sentence need not necessarily follow from the first one, or contradict the first one, you would say it is \"Neutral\".\n",
      "If the second sentence logically follows from the first sentence, you would say it is \"Entailment\".\n",
      "Also study the examples below.\n",
      "Consider the two sentences: \"A man, woman, and child enjoying themselves on a beach.\" and\n",
      "\"A family of three is at the mall shopping.\". Let's think step by step. The family cannot be at the beach and at the mall at the same time, so the second sentence contradicts the first one and does not follow from the first one, and it is an example of \"Contradiction\" category.\n",
      "\n",
      "Consider the two sentences: \"A woman wearing all white and eating, walks next to a man holding a briefcase.\" and\n",
      "\"A married couple is walking next to each other.\". Let's think step by step. The man and woman walking next to each other on road need not be related to each other, so the second sentence neither contradicts nor follows from the first one, and it is an example of \"Neutral\" category.\n",
      "\n",
      "Consider the two sentences: \"People waiting to get on a train or just getting off.\" and\n",
      "\"There are people just getting on a train.\". Let's think step by step. As some people were waiting to get on the train, they would definitely get on the train, so the second sentence does not contradict the first one and it logically follows from the first one, and it is an example of \"Entailment\" category.\n",
      "\n",
      "Consider the two sentences: \"A person on a horse jumps over a broken down airplane.\" and\n",
      "\"A person is training his horse for a competition.\". Let's think step by step. The horse jumping over the broken down airplane is not related to the person training his horse for a competition, so the second sentence does not contradict the first one and it logically follows from the first one, and it is an example of \"Entailment\" category.\n",
      "\n",
      "Consider the two sentences: \"A man and a woman are sitting on a bus.\" and\n",
      "\"\n",
      "Correct label: neutral\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "generating for i: 2/6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pretty printed output:\n",
      "----------------------------------------------------------------------------------------------------\n",
      "I will give you two sentences, you need to tell me which category the pair of sentences belong to.\n",
      "There are three categories: \"Contradiction\", \"Neutral\" and \"Entailment\".\n",
      "If the second sentence contradicts in any way to the first sentence, you would say it is \"Contradiction\".\n",
      "If no conclusion can be drawn, or the second sentence need not necessarily follow from the first one, or contradict the first one, you would say it is \"Neutral\".\n",
      "If the second sentence logically follows from the first sentence, you would say it is \"Entailment\".\n",
      "Also study the examples below.\n",
      "Consider the two sentences: \"A man, woman, and child enjoying themselves on a beach.\" and\n",
      "\"A family of three is at the mall shopping.\". Let's think step by step. The family cannot be at the beach and at the mall at the same time, so the second sentence contradicts the first one and does not follow from the first one, and it is an example of \"Contradiction\" category.\n",
      "\n",
      "Consider the two sentences: \"A woman wearing all white and eating, walks next to a man holding a briefcase.\" and\n",
      "\"A married couple is walking next to each other.\". Let's think step by step. The man and woman walking next to each other on road need not be related to each other, so the second sentence neither contradicts nor follows from the first one, and it is an example of \"Neutral\" category.\n",
      "\n",
      "Consider the two sentences: \"People waiting to get on a train or just getting off.\" and\n",
      "\"There are people just getting on a train.\". Let's think step by step. As some people were waiting to get on the train, they would definitely get on the train, so the second sentence does not contradict the first one and it logically follows from the first one, and it is an example of \"Entailment\" category.\n",
      "\n",
      "Consider the two sentences: \"A person on a horse jumps over a broken down airplane.\" and\n",
      "\"A person is outdoors, on a horse.\". Let's think step by step. As some people were on a horse, they would definitely jump over the broken down airplane, so the second sentence does not contradict the first one and it logically follows from the first one, and it is an example of \"Entailment\" category.\n",
      "\n",
      "Consider the two sentences: \"A man is on a boat in the water.\" and\n",
      "\"A man is on\n",
      "Correct label: entailment\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "generating for i: 3/6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pretty printed output:\n",
      "----------------------------------------------------------------------------------------------------\n",
      "I will give you two sentences, you need to tell me which category the pair of sentences belong to.\n",
      "There are three categories: \"Contradiction\", \"Neutral\" and \"Entailment\".\n",
      "If the second sentence contradicts in any way to the first sentence, you would say it is \"Contradiction\".\n",
      "If no conclusion can be drawn, or the second sentence need not necessarily follow from the first one, or contradict the first one, you would say it is \"Neutral\".\n",
      "If the second sentence logically follows from the first sentence, you would say it is \"Entailment\".\n",
      "Also study the examples below.\n",
      "Consider the two sentences: \"A man, woman, and child enjoying themselves on a beach.\" and\n",
      "\"A family of three is at the mall shopping.\". Let's think step by step. The family cannot be at the beach and at the mall at the same time, so the second sentence contradicts the first one and does not follow from the first one, and it is an example of \"Contradiction\" category.\n",
      "\n",
      "Consider the two sentences: \"A woman wearing all white and eating, walks next to a man holding a briefcase.\" and\n",
      "\"A married couple is walking next to each other.\". Let's think step by step. The man and woman walking next to each other on road need not be related to each other, so the second sentence neither contradicts nor follows from the first one, and it is an example of \"Neutral\" category.\n",
      "\n",
      "Consider the two sentences: \"People waiting to get on a train or just getting off.\" and\n",
      "\"There are people just getting on a train.\". Let's think step by step. As some people were waiting to get on the train, they would definitely get on the train, so the second sentence does not contradict the first one and it logically follows from the first one, and it is an example of \"Entailment\" category.\n",
      "\n",
      "Consider the two sentences: \"Children smiling and waving at camera.\" and\n",
      "\"There are children present.\". Let's think step by step. As some children were present, they would definitely be present, so the second sentence logically follows from the first one and it is an example of \"Entailment\" category.\n",
      "\n",
      "Consider the two sentences: \"A man and woman are walking past a park.\" and\n",
      "\"A woman and man are walking past a park.\". Let's think step by step. The\n",
      "Correct label: entailment\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "generating for i: 4/6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pretty printed output:\n",
      "----------------------------------------------------------------------------------------------------\n",
      "I will give you two sentences, you need to tell me which category the pair of sentences belong to.\n",
      "There are three categories: \"Contradiction\", \"Neutral\" and \"Entailment\".\n",
      "If the second sentence contradicts in any way to the first sentence, you would say it is \"Contradiction\".\n",
      "If no conclusion can be drawn, or the second sentence need not necessarily follow from the first one, or contradict the first one, you would say it is \"Neutral\".\n",
      "If the second sentence logically follows from the first sentence, you would say it is \"Entailment\".\n",
      "Also study the examples below.\n",
      "Consider the two sentences: \"A man, woman, and child enjoying themselves on a beach.\" and\n",
      "\"A family of three is at the mall shopping.\". Let's think step by step. The family cannot be at the beach and at the mall at the same time, so the second sentence contradicts the first one and does not follow from the first one, and it is an example of \"Contradiction\" category.\n",
      "\n",
      "Consider the two sentences: \"A woman wearing all white and eating, walks next to a man holding a briefcase.\" and\n",
      "\"A married couple is walking next to each other.\". Let's think step by step. The man and woman walking next to each other on road need not be related to each other, so the second sentence neither contradicts nor follows from the first one, and it is an example of \"Neutral\" category.\n",
      "\n",
      "Consider the two sentences: \"People waiting to get on a train or just getting off.\" and\n",
      "\"There are people just getting on a train.\". Let's think step by step. As some people were waiting to get on the train, they would definitely get on the train, so the second sentence does not contradict the first one and it logically follows from the first one, and it is an example of \"Entailment\" category.\n",
      "\n",
      "Consider the two sentences: \"A boy is jumping on skateboard in the middle of a red bridge.\" and\n",
      "\"The boy skates down the sidewalk.\". Let's think step by step. The boy jumping on the skateboard is definitely not jumping on the sidewalk, so the second sentence does not contradict the first one, and it logically follows from the first one, and it is an example of \"Contradiction\" category.\n",
      "\n",
      "Consider the two sentences: \"The woman is walking next to the man who is holding a briefcase.\" and\n",
      "\"The\n",
      "Correct label: contradiction\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "generating for i: 5/6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pretty printed output:\n",
      "----------------------------------------------------------------------------------------------------\n",
      "I will give you two sentences, you need to tell me which category the pair of sentences belong to.\n",
      "There are three categories: \"Contradiction\", \"Neutral\" and \"Entailment\".\n",
      "If the second sentence contradicts in any way to the first sentence, you would say it is \"Contradiction\".\n",
      "If no conclusion can be drawn, or the second sentence need not necessarily follow from the first one, or contradict the first one, you would say it is \"Neutral\".\n",
      "If the second sentence logically follows from the first sentence, you would say it is \"Entailment\".\n",
      "Also study the examples below.\n",
      "Consider the two sentences: \"A man, woman, and child enjoying themselves on a beach.\" and\n",
      "\"A family of three is at the mall shopping.\". Let's think step by step. The family cannot be at the beach and at the mall at the same time, so the second sentence contradicts the first one and does not follow from the first one, and it is an example of \"Contradiction\" category.\n",
      "\n",
      "Consider the two sentences: \"A woman wearing all white and eating, walks next to a man holding a briefcase.\" and\n",
      "\"A married couple is walking next to each other.\". Let's think step by step. The man and woman walking next to each other on road need not be related to each other, so the second sentence neither contradicts nor follows from the first one, and it is an example of \"Neutral\" category.\n",
      "\n",
      "Consider the two sentences: \"People waiting to get on a train or just getting off.\" and\n",
      "\"There are people just getting on a train.\". Let's think step by step. As some people were waiting to get on the train, they would definitely get on the train, so the second sentence does not contradict the first one and it logically follows from the first one, and it is an example of \"Entailment\" category.\n",
      "\n",
      "Consider the two sentences: \"An older man sits with his orange juice at a small table in a coffee shop while employees in bright colored shirts smile in the background.\" and\n",
      "\"An older man drinks his juice as he waits for his daughter to get off work.\". Let's think step by step. The older man is probably waiting for his daughter to get off work, so the second sentence does not contradict the first one and it logically follows from the first one, and it is an example of \"Contradiction\" category.\n",
      "\n",
      "Consider the two sentences: \"A woman and a man are sitting at a table.\" and\n",
      "\"A woman and a man are sitting\n",
      "Correct label: neutral\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "generating for i: 6/6\n",
      "Pretty printed output:\n",
      "----------------------------------------------------------------------------------------------------\n",
      "I will give you two sentences, you need to tell me which category the pair of sentences belong to.\n",
      "There are three categories: \"Contradiction\", \"Neutral\" and \"Entailment\".\n",
      "If the second sentence contradicts in any way to the first sentence, you would say it is \"Contradiction\".\n",
      "If no conclusion can be drawn, or the second sentence need not necessarily follow from the first one, or contradict the first one, you would say it is \"Neutral\".\n",
      "If the second sentence logically follows from the first sentence, you would say it is \"Entailment\".\n",
      "Also study the examples below.\n",
      "Consider the two sentences: \"A man, woman, and child enjoying themselves on a beach.\" and\n",
      "\"A family of three is at the mall shopping.\". Let's think step by step. The family cannot be at the beach and at the mall at the same time, so the second sentence contradicts the first one and does not follow from the first one, and it is an example of \"Contradiction\" category.\n",
      "\n",
      "Consider the two sentences: \"A woman wearing all white and eating, walks next to a man holding a briefcase.\" and\n",
      "\"A married couple is walking next to each other.\". Let's think step by step. The man and woman walking next to each other on road need not be related to each other, so the second sentence neither contradicts nor follows from the first one, and it is an example of \"Neutral\" category.\n",
      "\n",
      "Consider the two sentences: \"People waiting to get on a train or just getting off.\" and\n",
      "\"There are people just getting on a train.\". Let's think step by step. As some people were waiting to get on the train, they would definitely get on the train, so the second sentence does not contradict the first one and it logically follows from the first one, and it is an example of \"Entailment\" category.\n",
      "\n",
      "Consider the two sentences: \"High fashion ladies wait outside a tram beside a crowd of people in the city.\" and\n",
      "\"The women do not care what clothes they wear.\". Let's think step by step. The people in the crowd are not in high fashion, so the second sentence does not contradict the first one and it logically follows from the first one, and it is an example of \"Entailment\" category.\n",
      "\n",
      "Consider the two sentences: \"A man, woman, and child enjoying themselves on a beach.\" and\n",
      "\"A family of three is at the mall\n",
      "Correct label: contradiction\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"NLI Task\")\n",
    "print(f\"model has #params = {get_num_parameters(model)/10**6:.2f} M\")\n",
    "print(f\"model has size = {get_model_size(model)/MiB:.2f} MiB = {get_model_size(model)/GiB:.2f} GiB\")\n",
    "\n",
    "for idx, (s1, s2, gt) in enumerate(dataset):\n",
    "    print(f\"generating for i: {idx+1}/{len(dataset)}\")\n",
    "    prediction = model.generate(\n",
    "        prepare_input(s1, s2, prompt5_few_shot_cot_with_rules),\n",
    "        max_new_tokens=75,\n",
    "\n",
    "        # sampling decoding\n",
    "        do_sample=True,\n",
    "        temperature=0.4,\n",
    "\n",
    "        # num_beams=10,\n",
    "        # early_stopping=True,\n",
    "\n",
    "        # do_sample=True,\n",
    "        # top_k=3,\n",
    "\n",
    "        # do_sample=True,\n",
    "        # top_p=0.90,\n",
    "    )\n",
    "    pretty_print(prediction[0])\n",
    "    print(f\"Correct label: {gt}\")\n",
    "    print('\\n\\n\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## results and accuracy calculation\n",
    "for clarity, I rewrite only model's responses from the above cell to the tasks:\n",
    "\n",
    "- Consider the two sentences: \"A person on a horse jumps over a broken down airplane.\" and\n",
    "\"A person is training his horse for a competition.\". Let's think step by step. The horse jumping over the broken down airplane is not related to the person training his horse for a competition, so the second sentence does not contradict the first one and it logically follows from the first one, and it is an example of \"Entailment\" category. (**wrong** as Correct label: neutral)\n",
    "- Consider the two sentences: \"A person on a horse jumps over a broken down airplane.\" and\n",
    "\"A person is outdoors, on a horse.\". Let's think step by step. As some people were on a horse, they would definitely jump over the broken down airplane, so the second sentence does not contradict the first one and it logically follows from the first one, and it is an example of \"Entailment\" category. (**correct**)\n",
    "- Consider the two sentences: \"Children smiling and waving at camera.\" and\n",
    "\"There are children present.\". Let's think step by step. As some children were present, they would definitely be present, so the second sentence logically follows from the first one and it is an example of \"Entailment\" category. (**correct**)\n",
    "- Consider the two sentences: \"A boy is jumping on skateboard in the middle of a red bridge.\" and\n",
    "\"The boy skates down the sidewalk.\". Let's think step by step. The boy jumping on the skateboard is definitely not jumping on the sidewalk, so the second sentence does not contradict the first one, and it logically follows from the first one, and it is an example of \"Contradiction\" category. (**correct**, but reasoning is totally opposite!)\n",
    "- Consider the two sentences: \"An older man sits with his orange juice at a small table in a coffee shop while employees in bright colored shirts smile in the background.\" and\n",
    "\"An older man drinks his juice as he waits for his daughter to get off work.\". Let's think step by step. The older man is probably waiting for his daughter to get off work, so the second sentence does not contradict the first one and it logically follows from the first one, and it is an example of \"Contradiction\" category. (**wrong** as Correct label: neutral)\n",
    "- Consider the two sentences: \"High fashion ladies wait outside a tram beside a crowd of people in the city.\" and\n",
    "\"The women do not care what clothes they wear.\". Let's think step by step. The people in the crowd are not in high fashion, so the second sentence does not contradict the first one and it logically follows from the first one, and it is an example of \"Entailment\" category. (**wrong** as Correct label: contradiction)\n",
    "\n",
    "So Pythia-410M got $3/6$ correct (accuracy $50\\%$) for the NLI task with the **few shot cot with task description prompt**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "a_SMGsdUWfsI"
   },
   "source": [
    "## Pythia-410M on question answering task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wvRVZmGineXY",
    "outputId": "951d9ef0-efb2-421e-88bf-9b01c345d07e"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model has #params = 405.33 M\n",
      "model has size = 1546.23 MiB = 1.51 GiB\n",
      "generating for i: 1/6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pretty printed output:\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Please answer the following question: What is a great place to lay in the sun? Choose one of these four options: in the basement, west, solar system, beach, beans. The correct answer is: beach.\n",
      "\n",
      "Please answer the following question: What might be the result of a season of successful skiing? Choose one of these four options: finish line, broken bones, broken legs, chapped lips, healthy body. The correct answer is: healthy body.\n",
      "\n",
      "Please answer the following question: She loved buying products, she was driven by her what to shop more than any practical needs? Choose one of these four options: desire, money, time, credit, spending money. The correct answer is: desire.\n",
      "\n",
      "Please answer the following question: What might you feel after doing housework for hours? Choose one of these four options: anger, not boredom, stress, boredom, anxiety. The correct answer is: stress.\n",
      "\n",
      "Please answer the following question: The only baggage the woman checked was a drawstring bag, where was she heading with it? Choose one of these four options: garbage can, military, jewelry store, safe, airport. The correct answer is: military.\n",
      "\n",
      "Please answer the following question:\n",
      "Ground truth answer: airport\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "generating for i: 2/6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pretty printed output:\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Please answer the following question: What is a great place to lay in the sun? Choose one of these four options: in the basement, west, solar system, beach, beans. The correct answer is: beach.\n",
      "\n",
      "Please answer the following question: What might be the result of a season of successful skiing? Choose one of these four options: finish line, broken bones, broken legs, chapped lips, healthy body. The correct answer is: healthy body.\n",
      "\n",
      "Please answer the following question: She loved buying products, she was driven by her what to shop more than any practical needs? Choose one of these four options: desire, money, time, credit, spending money. The correct answer is: desire.\n",
      "\n",
      "Please answer the following question: What might you feel after doing housework for hours? Choose one of these four options: anger, not boredom, stress, boredom, anxiety. The correct answer is: stress.\n",
      "\n",
      "Please answer the following question: To prevent any glare during the big football game he made sure to clean the dust of his what? Choose one of these four options: television, attic, corner, they cannot clean corner and library during football match they cannot need that, ground. The correct answer is: ground.\n",
      "\n",
      "Please answer the following question:\n",
      "Ground truth answer: television\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "generating for i: 3/6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pretty printed output:\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Please answer the following question: What is a great place to lay in the sun? Choose one of these four options: in the basement, west, solar system, beach, beans. The correct answer is: beach.\n",
      "\n",
      "Please answer the following question: What might be the result of a season of successful skiing? Choose one of these four options: finish line, broken bones, broken legs, chapped lips, healthy body. The correct answer is: healthy body.\n",
      "\n",
      "Please answer the following question: She loved buying products, she was driven by her what to shop more than any practical needs? Choose one of these four options: desire, money, time, credit, spending money. The correct answer is: desire.\n",
      "\n",
      "Please answer the following question: What might you feel after doing housework for hours? Choose one of these four options: anger, not boredom, stress, boredom, anxiety. The correct answer is: stress.\n",
      "\n",
      "Please answer the following question: The president is the leader of what institution? Choose one of these four options: walmart, white house, country, corporation, government. The correct answer is: white house.\n",
      "\n",
      "Please answer the following question\n",
      "Ground truth answer: country\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "generating for i: 4/6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pretty printed output:\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Please answer the following question: What is a great place to lay in the sun? Choose one of these four options: in the basement, west, solar system, beach, beans. The correct answer is: beach.\n",
      "\n",
      "Please answer the following question: What might be the result of a season of successful skiing? Choose one of these four options: finish line, broken bones, broken legs, chapped lips, healthy body. The correct answer is: healthy body.\n",
      "\n",
      "Please answer the following question: She loved buying products, she was driven by her what to shop more than any practical needs? Choose one of these four options: desire, money, time, credit, spending money. The correct answer is: desire.\n",
      "\n",
      "Please answer the following question: What might you feel after doing housework for hours? Choose one of these four options: anger, not boredom, stress, boredom, anxiety. The correct answer is: stress.\n",
      "\n",
      "Please answer the following question: What kind of driving leads to accidents? Choose one of these four options: stressful, dangerous, fun, illegal, deadly. The correct answer is: dangerous.\n",
      "\n",
      "Please answer the following question:\n",
      "Ground truth answer: dangerous\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "generating for i: 5/6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pretty printed output:\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Please answer the following question: What is a great place to lay in the sun? Choose one of these four options: in the basement, west, solar system, beach, beans. The correct answer is: beach.\n",
      "\n",
      "Please answer the following question: What might be the result of a season of successful skiing? Choose one of these four options: finish line, broken bones, broken legs, chapped lips, healthy body. The correct answer is: healthy body.\n",
      "\n",
      "Please answer the following question: She loved buying products, she was driven by her what to shop more than any practical needs? Choose one of these four options: desire, money, time, credit, spending money. The correct answer is: desire.\n",
      "\n",
      "Please answer the following question: What might you feel after doing housework for hours? Choose one of these four options: anger, not boredom, stress, boredom, anxiety. The correct answer is: stress.\n",
      "\n",
      "Please answer the following question: Can you name a good reason for attending school? Choose one of these four options: get smart, boredom, colds and flu, taking tests, spend time. The correct answer is: get smart.\n",
      "\n",
      "Please answer the following question\n",
      "Ground truth answer: \"get smart\"\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "generating for i: 6/6\n",
      "Pretty printed output:\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Please answer the following question: What is a great place to lay in the sun? Choose one of these four options: in the basement, west, solar system, beach, beans. The correct answer is: beach.\n",
      "\n",
      "Please answer the following question: What might be the result of a season of successful skiing? Choose one of these four options: finish line, broken bones, broken legs, chapped lips, healthy body. The correct answer is: healthy body.\n",
      "\n",
      "Please answer the following question: She loved buying products, she was driven by her what to shop more than any practical needs? Choose one of these four options: desire, money, time, credit, spending money. The correct answer is: desire.\n",
      "\n",
      "Please answer the following question: What might you feel after doing housework for hours? Choose one of these four options: anger, not boredom, stress, boredom, anxiety. The correct answer is: stress.\n",
      "\n",
      "Please answer the following question: Stanley had a dream that was very vivid and scary. He had trouble telling it from what? Choose one of these four options: imagination, reality, dreamworker, nightmare, awake. The correct answer is: dreamworker.\n",
      "\n",
      "Please answer the following question\n",
      "Ground truth answer: reality\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(f\"model has #params = {get_num_parameters(model)/10**6:.2f} M\")\n",
    "print(f\"model has size = {get_model_size(model)/MiB:.2f} MiB = {get_model_size(model)/GiB:.2f} GiB\")\n",
    "for idx, (q, c, ans) in enumerate(dataset2):\n",
    "    print(f\"generating for i: {idx+1}/{len(dataset2)}\")\n",
    "    prediction = model.generate(\n",
    "        prepare_input(q, c, qa_prompt_few_shot),\n",
    "        max_new_tokens=10,\n",
    "\n",
    "        do_sample=True,\n",
    "        temperature=0.4,\n",
    "\n",
    "        # num_beams=10,\n",
    "        # early_stopping=True,\n",
    "\n",
    "        # do_sample=True,\n",
    "        # top_k=3,\n",
    "\n",
    "        # do_sample=True,\n",
    "        # top_p=0.90,\n",
    "    )\n",
    "    pretty_print(prediction[0])\n",
    "    print(f\"Ground truth answer: {ans}\")\n",
    "    print('\\n\\n\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_3Ehcvf_necd"
   },
   "source": [
    "## results and accuracy calculation\n",
    "\n",
    "for clarity, I rewrite only model's responses to the questions:\n",
    "- Please answer the following question: The only baggage the woman checked was a drawstring bag, where was she heading with it? Choose one of these four options: garbage can, military, jewelry store, safe, airport. The correct answer is: military. (**wrong** as answer: airport)\n",
    "- Please answer the following question: To prevent any glare during the big football game he made sure to clean the dust of his what? Choose one of these four options: television, attic, corner, they cannot clean corner and library during football match they cannot need that, ground. The correct answer is: ground. (**wrong** as answer: television)\n",
    "- Please answer the following question: The president is the leader of what institution? Choose one of these four options: walmart, white house, country, corporation, government. The correct answer is: white house. (**wrong** as answer: country)\n",
    "- Please answer the following question: What kind of driving leads to accidents? Choose one of these four options: stressful, dangerous, fun, illegal, deadly. The correct answer is: dangerous. (**correct**)\n",
    "- Please answer the following question: Can you name a good reason for attending school? Choose one of these four options: get smart, boredom, colds and flu, taking tests, spend time. The correct answer is: get smart. (**correct**)\n",
    "- Please answer the following question: Stanley had a dream that was very vivid and scary. He had trouble telling it from what? Choose one of these four options: imagination, reality, dreamworker, nightmare, awake. The correct answer is: dreamworker. (**wrong** as answer: reality)\n",
    "\n",
    "So on the QA task with the few shot prompt, Pythia-410M gets $2/6$ correct, accuracy $33.3\\%$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2S6nuYo4yY4C"
   },
   "source": [
    "# Pythia-1.4B model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 194,
     "referenced_widgets": [
      "b9f1b1dacebb479dad091c876a706fc0",
      "688cbf78b1b54477a8eb838857274bf9",
      "05bf0a28c84a4c408e29f46db5c34d27",
      "ab8c7ae66f8e49bf822aa3a1014dbe7f",
      "e0fed210c6ee4bbca6ef9a82dd82495e",
      "a97910162a4f4a5496e1d90b8c4e4597",
      "dafb02b0e0c54e7ca821214294c07361",
      "0024448720c24de981df36b5b36b6b02",
      "acc6cb9cde0c48d7a3625f11a519a187",
      "4f4768358f4c43d289d1ff6e907b9a49",
      "9e3c672f09ab441d91f3ee317dca2d1d",
      "6f735657edca43398b81e8c9d890456a",
      "37336632630b437cb0feb30f5e19cc9f",
      "79e34d4d3e13459f8e45f7195b2f6fdd",
      "882b993f9a5643ca88bd7ad1e1989ccd",
      "d77fb48c43d845a98d6f6a1adcaee2af",
      "29954e292761402389646eeb530af315",
      "fc88234ce5124bccab1517331aeb2a2d",
      "28a5a9475c6a46a4b96df96bfeef4f4f",
      "e6a894b83744426a9a7e775f9c28b87b",
      "2c95d6fe0af04873be673e1b981d201d",
      "0d1596ac5ff04df899c5c73dce953796",
      "28764f61414e4af3949b1506aab1e850",
      "4324d53817df4253b310d5cb2c13a3ae",
      "88de360dfd4d4027b25fde35d986e508",
      "7b53c1e5c8994c9794dbe4de01cb3bbf",
      "23cecadb1aca40b291112fd10502ddb7",
      "c8979dfc77ea455dbc5feababc45089e",
      "b11d03c1c3024dd0ad1d5e04e21e0de1",
      "030d3b89b1a6437f88c2828610222028",
      "dca9bd6f8a0144d3be5ef1edea540b3d",
      "a2ffe451540c480c8da8a3a7b742c187",
      "f15700a62d7f4d32982e562f5102e4d4",
      "aa7d30d58ad849bcb9028f3f320847cc",
      "38259baaed4042f58df7fa9709eac42f",
      "3d7a4af6d2f8400482d3db15fb1bcba1",
      "a2d27d835c3049eb8c76a341075d6385",
      "2767a8a66763411caa4e091725ab784f",
      "2b5201b0436044d9a660d12253498c77",
      "b5a92ee07e1d4468a0fab1ddda974404",
      "5c2f751f4b224dcb8671e786cf721dbc",
      "94712a9fb31c4a1481d090a17c736a4d",
      "99304db5d8de41d6bca696316c434c13",
      "962871510b174289bddb3900d5e747bb",
      "30dcbaa35d66460da9c5d99787a478de",
      "4e5965f7ae42492fac9aa2b653199b58",
      "89e8baa7a16940c5a18e903ecef82020",
      "a04048dc9dbc431eb5b87f462a7eb8bd",
      "47d464339753493fb2e274dce3b88368",
      "8641b5c946dd44c6974c8bd1e3396710",
      "743320a97e1c4516ba27f4ef7ed8314e",
      "6308fc726ac04ab6a75355a2bbbb13b0",
      "3d19c1f02f1c4ed5b6a8fe7c97baf11f",
      "bfe93d9024d04e38a11c71ac5f06512e",
      "8cdd3c5c44b24b27aeab6efb6445925b"
     ]
    },
    "id": "KUA5t8ngxMQ3",
    "outputId": "b6daa69d-8066-4a95-925f-667dd32d6ec6"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b9f1b1dacebb479dad091c876a706fc0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/396 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6f735657edca43398b81e8c9d890456a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/2.11M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "28764f61414e4af3949b1506aab1e850",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/99.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aa7d30d58ad849bcb9028f3f320847cc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/570 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "30dcbaa35d66460da9c5d99787a478de",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/2.93G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# pythia was not instruction finetuned, so it might have a hard time following structured texts.\n",
    "# try by making the prompt a paragraph and see if it follows.\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"EleutherAI/Pythia-1.4b\")\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    \"EleutherAI/Pythia-1.4b\",\n",
    "    # trust_remote_code=True,\n",
    "    # torch_dtype=torch.float16,\n",
    ").to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rLcyFIiAmfen"
   },
   "source": [
    "## Pythia-1.4B on NLI task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8S9AWUowyH7o",
    "outputId": "6e2ca381-2598-4ce8-c50f-ef1445b49347"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NLI Task\n",
      "model has #params = 1414.65 M\n",
      "model has size = 5396.45 MiB = 5.27 GiB\n",
      "generating for i: 1/6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pretty printed output:\n",
      "----------------------------------------------------------------------------------------------------\n",
      "I will give you two sentences, you need to tell me which category the pair of sentences belong to.\n",
      "There are three categories: \"Contradiction\", \"Neutral\" and \"Entailment\".\n",
      "If the second sentence contradicts in any way to the first sentence, you would say it is \"Contradiction\".\n",
      "If no conclusion can be drawn, or the second sentence need not necessarily follow from the first one, or contradict the first one, you would say it is \"Neutral\".\n",
      "If the second sentence logically follows from the first sentence, you would say it is \"Entailment\".\n",
      "Also study the examples below.\n",
      "Consider the two sentences: \"A man, woman, and child enjoying themselves on a beach.\" and\n",
      "\"A family of three is at the mall shopping.\". Let's think step by step. The family cannot be at the beach and at the mall at the same time, so the second sentence contradicts the first one and does not follow from the first one, and it is an example of \"Contradiction\" category.\n",
      "\n",
      "Consider the two sentences: \"A woman wearing all white and eating, walks next to a man holding a briefcase.\" and\n",
      "\"A married couple is walking next to each other.\". Let's think step by step. The man and woman walking next to each other on road need not be related to each other, so the second sentence neither contradicts nor follows from the first one, and it is an example of \"Neutral\" category.\n",
      "\n",
      "Consider the two sentences: \"People waiting to get on a train or just getting off.\" and\n",
      "\"There are people just getting on a train.\". Let's think step by step. As some people were waiting to get on the train, they would definitely get on the train, so the second sentence does not contradict the first one and it logically follows from the first one, and it is an example of \"Entailment\" category.\n",
      "\n",
      "Consider the two sentences: \"A person on a horse jumps over a broken down airplane.\" and\n",
      "\"A person is training his horse for a competition.\". Let's think step by step. The person on the horse jumping over the airplane is not the same as the person training the horse for the competition, so the second sentence neither contradicts nor follows from the first one, and it is an example of \"Neutral\" category.\n",
      "\n",
      "Consider the two sentences: \"A man and woman are standing at the foot of a mountain.\" and\n",
      "\"A man and\n",
      "Correct label: neutral\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "generating for i: 2/6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pretty printed output:\n",
      "----------------------------------------------------------------------------------------------------\n",
      "I will give you two sentences, you need to tell me which category the pair of sentences belong to.\n",
      "There are three categories: \"Contradiction\", \"Neutral\" and \"Entailment\".\n",
      "If the second sentence contradicts in any way to the first sentence, you would say it is \"Contradiction\".\n",
      "If no conclusion can be drawn, or the second sentence need not necessarily follow from the first one, or contradict the first one, you would say it is \"Neutral\".\n",
      "If the second sentence logically follows from the first sentence, you would say it is \"Entailment\".\n",
      "Also study the examples below.\n",
      "Consider the two sentences: \"A man, woman, and child enjoying themselves on a beach.\" and\n",
      "\"A family of three is at the mall shopping.\". Let's think step by step. The family cannot be at the beach and at the mall at the same time, so the second sentence contradicts the first one and does not follow from the first one, and it is an example of \"Contradiction\" category.\n",
      "\n",
      "Consider the two sentences: \"A woman wearing all white and eating, walks next to a man holding a briefcase.\" and\n",
      "\"A married couple is walking next to each other.\". Let's think step by step. The man and woman walking next to each other on road need not be related to each other, so the second sentence neither contradicts nor follows from the first one, and it is an example of \"Neutral\" category.\n",
      "\n",
      "Consider the two sentences: \"People waiting to get on a train or just getting off.\" and\n",
      "\"There are people just getting on a train.\". Let's think step by step. As some people were waiting to get on the train, they would definitely get on the train, so the second sentence does not contradict the first one and it logically follows from the first one, and it is an example of \"Entailment\" category.\n",
      "\n",
      "Consider the two sentences: \"A person on a horse jumps over a broken down airplane.\" and\n",
      "\"A person is outdoors, on a horse.\". Let's think step by step. The person on a horse jumping over the airplane is not necessarily related to the person outdoors, so the second sentence does not contradict the first one and it logically follows from the first one, and it is an example of \"Entailment\" category.\n",
      "\n",
      "Here is a list of all the categories and examples.\n",
      "\n",
      "A:\n",
      "\n",
      "The two sentences are not contradict\n",
      "Correct label: entailment\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "generating for i: 3/6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pretty printed output:\n",
      "----------------------------------------------------------------------------------------------------\n",
      "I will give you two sentences, you need to tell me which category the pair of sentences belong to.\n",
      "There are three categories: \"Contradiction\", \"Neutral\" and \"Entailment\".\n",
      "If the second sentence contradicts in any way to the first sentence, you would say it is \"Contradiction\".\n",
      "If no conclusion can be drawn, or the second sentence need not necessarily follow from the first one, or contradict the first one, you would say it is \"Neutral\".\n",
      "If the second sentence logically follows from the first sentence, you would say it is \"Entailment\".\n",
      "Also study the examples below.\n",
      "Consider the two sentences: \"A man, woman, and child enjoying themselves on a beach.\" and\n",
      "\"A family of three is at the mall shopping.\". Let's think step by step. The family cannot be at the beach and at the mall at the same time, so the second sentence contradicts the first one and does not follow from the first one, and it is an example of \"Contradiction\" category.\n",
      "\n",
      "Consider the two sentences: \"A woman wearing all white and eating, walks next to a man holding a briefcase.\" and\n",
      "\"A married couple is walking next to each other.\". Let's think step by step. The man and woman walking next to each other on road need not be related to each other, so the second sentence neither contradicts nor follows from the first one, and it is an example of \"Neutral\" category.\n",
      "\n",
      "Consider the two sentences: \"People waiting to get on a train or just getting off.\" and\n",
      "\"There are people just getting on a train.\". Let's think step by step. As some people were waiting to get on the train, they would definitely get on the train, so the second sentence does not contradict the first one and it logically follows from the first one, and it is an example of \"Entailment\" category.\n",
      "\n",
      "Consider the two sentences: \"Children smiling and waving at camera.\" and\n",
      "\"There are children present.\". Let's think step by step. The children need not be present for the camera to be there, so the second sentence logically follows from the first one, and it is an example of \"Entailment\" category.\n",
      "\n",
      "Consider the two sentences: \"A man, woman, and child enjoying themselves on a beach.\" and\n",
      "\"A family of three is at the mall shopping.\". Let's think\n",
      "Correct label: entailment\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "generating for i: 4/6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pretty printed output:\n",
      "----------------------------------------------------------------------------------------------------\n",
      "I will give you two sentences, you need to tell me which category the pair of sentences belong to.\n",
      "There are three categories: \"Contradiction\", \"Neutral\" and \"Entailment\".\n",
      "If the second sentence contradicts in any way to the first sentence, you would say it is \"Contradiction\".\n",
      "If no conclusion can be drawn, or the second sentence need not necessarily follow from the first one, or contradict the first one, you would say it is \"Neutral\".\n",
      "If the second sentence logically follows from the first sentence, you would say it is \"Entailment\".\n",
      "Also study the examples below.\n",
      "Consider the two sentences: \"A man, woman, and child enjoying themselves on a beach.\" and\n",
      "\"A family of three is at the mall shopping.\". Let's think step by step. The family cannot be at the beach and at the mall at the same time, so the second sentence contradicts the first one and does not follow from the first one, and it is an example of \"Contradiction\" category.\n",
      "\n",
      "Consider the two sentences: \"A woman wearing all white and eating, walks next to a man holding a briefcase.\" and\n",
      "\"A married couple is walking next to each other.\". Let's think step by step. The man and woman walking next to each other on road need not be related to each other, so the second sentence neither contradicts nor follows from the first one, and it is an example of \"Neutral\" category.\n",
      "\n",
      "Consider the two sentences: \"People waiting to get on a train or just getting off.\" and\n",
      "\"There are people just getting on a train.\". Let's think step by step. As some people were waiting to get on the train, they would definitely get on the train, so the second sentence does not contradict the first one and it logically follows from the first one, and it is an example of \"Entailment\" category.\n",
      "\n",
      "Consider the two sentences: \"A boy is jumping on skateboard in the middle of a red bridge.\" and\n",
      "\"The boy skates down the sidewalk.\". Let's think step by step. The boy jumping on the skateboard in the middle of the red bridge is not related to the boy skating down the sidewalk, so the second sentence does not contradict the first one and it logically follows from the first one, and it is an example of \"Neutral\" category.\n",
      "\n",
      "Consider the two sentences: \"A man is walking down a street with a dog.\"\n",
      "Correct label: contradiction\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "generating for i: 5/6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pretty printed output:\n",
      "----------------------------------------------------------------------------------------------------\n",
      "I will give you two sentences, you need to tell me which category the pair of sentences belong to.\n",
      "There are three categories: \"Contradiction\", \"Neutral\" and \"Entailment\".\n",
      "If the second sentence contradicts in any way to the first sentence, you would say it is \"Contradiction\".\n",
      "If no conclusion can be drawn, or the second sentence need not necessarily follow from the first one, or contradict the first one, you would say it is \"Neutral\".\n",
      "If the second sentence logically follows from the first sentence, you would say it is \"Entailment\".\n",
      "Also study the examples below.\n",
      "Consider the two sentences: \"A man, woman, and child enjoying themselves on a beach.\" and\n",
      "\"A family of three is at the mall shopping.\". Let's think step by step. The family cannot be at the beach and at the mall at the same time, so the second sentence contradicts the first one and does not follow from the first one, and it is an example of \"Contradiction\" category.\n",
      "\n",
      "Consider the two sentences: \"A woman wearing all white and eating, walks next to a man holding a briefcase.\" and\n",
      "\"A married couple is walking next to each other.\". Let's think step by step. The man and woman walking next to each other on road need not be related to each other, so the second sentence neither contradicts nor follows from the first one, and it is an example of \"Neutral\" category.\n",
      "\n",
      "Consider the two sentences: \"People waiting to get on a train or just getting off.\" and\n",
      "\"There are people just getting on a train.\". Let's think step by step. As some people were waiting to get on the train, they would definitely get on the train, so the second sentence does not contradict the first one and it logically follows from the first one, and it is an example of \"Entailment\" category.\n",
      "\n",
      "Consider the two sentences: \"An older man sits with his orange juice at a small table in a coffee shop while employees in bright colored shirts smile in the background.\" and\n",
      "\"An older man drinks his juice as he waits for his daughter to get off work.\". Let's think step by step. The coffee shop is not a place where people are waiting to get on a train, so the second sentence does not contradict the first one and it logically follows from the first one, and it is an example of \"Entailment\" category.\n",
      "\n",
      "Consider the two sentences: \"A man, woman, and child playing in a park.\" and\n",
      "\"A family of\n",
      "Correct label: neutral\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "generating for i: 6/6\n",
      "Pretty printed output:\n",
      "----------------------------------------------------------------------------------------------------\n",
      "I will give you two sentences, you need to tell me which category the pair of sentences belong to.\n",
      "There are three categories: \"Contradiction\", \"Neutral\" and \"Entailment\".\n",
      "If the second sentence contradicts in any way to the first sentence, you would say it is \"Contradiction\".\n",
      "If no conclusion can be drawn, or the second sentence need not necessarily follow from the first one, or contradict the first one, you would say it is \"Neutral\".\n",
      "If the second sentence logically follows from the first sentence, you would say it is \"Entailment\".\n",
      "Also study the examples below.\n",
      "Consider the two sentences: \"A man, woman, and child enjoying themselves on a beach.\" and\n",
      "\"A family of three is at the mall shopping.\". Let's think step by step. The family cannot be at the beach and at the mall at the same time, so the second sentence contradicts the first one and does not follow from the first one, and it is an example of \"Contradiction\" category.\n",
      "\n",
      "Consider the two sentences: \"A woman wearing all white and eating, walks next to a man holding a briefcase.\" and\n",
      "\"A married couple is walking next to each other.\". Let's think step by step. The man and woman walking next to each other on road need not be related to each other, so the second sentence neither contradicts nor follows from the first one, and it is an example of \"Neutral\" category.\n",
      "\n",
      "Consider the two sentences: \"People waiting to get on a train or just getting off.\" and\n",
      "\"There are people just getting on a train.\". Let's think step by step. As some people were waiting to get on the train, they would definitely get on the train, so the second sentence does not contradict the first one and it logically follows from the first one, and it is an example of \"Entailment\" category.\n",
      "\n",
      "Consider the two sentences: \"High fashion ladies wait outside a tram beside a crowd of people in the city.\" and\n",
      "\"The women do not care what clothes they wear.\". Let's think step by step. The tram is not a place where people are waiting to get on the train, so the second sentence does not contradict the first one, and it logically follows from the first one, and it is an example of \"Neutral\" category.\n",
      "\n",
      "Consider the two sentences: \"A man and woman are walking in the park.\" and\n",
      "\"A man and woman are walking\n",
      "Correct label: contradiction\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"NLI Task\")\n",
    "print(f\"model has #params = {get_num_parameters(model)/10**6:.2f} M\")\n",
    "print(f\"model has size = {get_model_size(model)/MiB:.2f} MiB = {get_model_size(model)/GiB:.2f} GiB\")\n",
    "\n",
    "for idx, (s1, s2, gt) in enumerate(dataset):\n",
    "    print(f\"generating for i: {idx+1}/{len(dataset)}\")\n",
    "    prediction = model.generate(\n",
    "        prepare_input(s1, s2, prompt5_few_shot_cot_with_rules),\n",
    "        max_new_tokens=75,\n",
    "\n",
    "        # sampling decoding\n",
    "        do_sample=True,\n",
    "        temperature=0.4,\n",
    "\n",
    "        # num_beams=10,\n",
    "        # early_stopping=True,\n",
    "\n",
    "        # do_sample=True,\n",
    "        # top_k=3,\n",
    "\n",
    "        # do_sample=True,\n",
    "        # top_p=0.90,\n",
    "    )\n",
    "    pretty_print(prediction[0])\n",
    "    print(f\"Correct label: {gt}\")\n",
    "    print('\\n\\n\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0Yu73URByIFm"
   },
   "source": [
    "## results and accuracy calculation\n",
    "\n",
    "for clarity, I rewrite only model's responses from the above cell to the tasks:\n",
    "\n",
    "- Consider the two sentences: \"A person on a horse jumps over a broken down airplane.\" and\n",
    "\"A person is training his horse for a competition.\". Let's think step by step. The person on the horse jumping over the airplane is not the same as the person training the horse for the competition, so the second sentence neither contradicts nor follows from the first one, and it is an example of \"Neutral\" category. (**correct**)\n",
    "- Consider the two sentences: \"A person on a horse jumps over a broken down airplane.\" and\n",
    "\"A person is outdoors, on a horse.\". Let's think step by step. The person on a horse jumping over the airplane is not necessarily related to the person outdoors, so the second sentence does not contradict the first one and it logically follows from the first one, and it is an example of \"Entailment\" category. (**correct**)\n",
    "- Consider the two sentences: \"Children smiling and waving at camera.\" and\n",
    "\"There are children present.\". Let's think step by step. The children need not be present for the camera to be there, so the second sentence logically follows from the first one, and it is an example of \"Entailment\" category. (**correct** but with incorrect reasoning may be)\n",
    "- Consider the two sentences: \"A boy is jumping on skateboard in the middle of a red bridge.\" and\n",
    "\"The boy skates down the sidewalk.\". Let's think step by step. The boy jumping on the skateboard in the middle of the red bridge is not related to the boy skating down the sidewalk, so the second sentence does not contradict the first one and it logically follows from the first one, and it is an example of \"Neutral\" category. (**wrong**, Correct label: contradiction)\n",
    "- Consider the two sentences: \"An older man sits with his orange juice at a small table in a coffee shop while employees in bright colored shirts smile in the background.\" and\n",
    "\"An older man drinks his juice as he waits for his daughter to get off work.\". Let's think step by step. The coffee shop is not a place where people are waiting to get on a train, so the second sentence does not contradict the first one and it logically follows from the first one, and it is an example of \"Entailment\" category. (**wrong** as Correct label: neutral)\n",
    "- Consider the two sentences: \"High fashion ladies wait outside a tram beside a crowd of people in the city.\" and\n",
    "\"The women do not care what clothes they wear.\". Let's think step by step. The tram is not a place where people are waiting to get on the train, so the second sentence does not contradict the first one, and it logically follows from the first one, and it is an example of \"Neutral\" category. (**wrong** as Correct label: contradiction)\n",
    "\n",
    "So Pythia-1.4B also got $3/6$ correct (accuracy $50\\%$) for the NLI task with the **few shot cot with task description prompt**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "53Dh-T2OKWi5"
   },
   "source": [
    "## Pythia-1.4B on question answering task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "INoiVhq9xMYu",
    "outputId": "4ee6c43c-b604-46e3-dd42-195ea4568f5d"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model has #params = 1414.65 M\n",
      "model has size = 5396.45 MiB = 5.27 GiB\n",
      "generating for i: 1/6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pretty printed output:\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Please answer the following question: What is a great place to lay in the sun? Choose one of these four options: in the basement, west, solar system, beach, beans. The correct answer is: beach.\n",
      "\n",
      "Please answer the following question: What might be the result of a season of successful skiing? Choose one of these four options: finish line, broken bones, broken legs, chapped lips, healthy body. The correct answer is: healthy body.\n",
      "\n",
      "Please answer the following question: She loved buying products, she was driven by her what to shop more than any practical needs? Choose one of these four options: desire, money, time, credit, spending money. The correct answer is: desire.\n",
      "\n",
      "Please answer the following question: What might you feel after doing housework for hours? Choose one of these four options: anger, not boredom, stress, boredom, anxiety. The correct answer is: stress.\n",
      "\n",
      "Please answer the following question: The only baggage the woman checked was a drawstring bag, where was she heading with it? Choose one of these four options: garbage can, military, jewelry store, safe, airport. The correct answer is: jewelry store.\n",
      "\n",
      "Please answer the following question\n",
      "Ground truth answer: airport\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "generating for i: 2/6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pretty printed output:\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Please answer the following question: What is a great place to lay in the sun? Choose one of these four options: in the basement, west, solar system, beach, beans. The correct answer is: beach.\n",
      "\n",
      "Please answer the following question: What might be the result of a season of successful skiing? Choose one of these four options: finish line, broken bones, broken legs, chapped lips, healthy body. The correct answer is: healthy body.\n",
      "\n",
      "Please answer the following question: She loved buying products, she was driven by her what to shop more than any practical needs? Choose one of these four options: desire, money, time, credit, spending money. The correct answer is: desire.\n",
      "\n",
      "Please answer the following question: What might you feel after doing housework for hours? Choose one of these four options: anger, not boredom, stress, boredom, anxiety. The correct answer is: stress.\n",
      "\n",
      "Please answer the following question: To prevent any glare during the big football game he made sure to clean the dust of his what? Choose one of these four options: television, attic, corner, they cannot clean corner and library during football match they cannot need that, ground. The correct answer is: ground.\n",
      "\n",
      "Please answer the following question:\n",
      "Ground truth answer: television\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "generating for i: 3/6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pretty printed output:\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Please answer the following question: What is a great place to lay in the sun? Choose one of these four options: in the basement, west, solar system, beach, beans. The correct answer is: beach.\n",
      "\n",
      "Please answer the following question: What might be the result of a season of successful skiing? Choose one of these four options: finish line, broken bones, broken legs, chapped lips, healthy body. The correct answer is: healthy body.\n",
      "\n",
      "Please answer the following question: She loved buying products, she was driven by her what to shop more than any practical needs? Choose one of these four options: desire, money, time, credit, spending money. The correct answer is: desire.\n",
      "\n",
      "Please answer the following question: What might you feel after doing housework for hours? Choose one of these four options: anger, not boredom, stress, boredom, anxiety. The correct answer is: stress.\n",
      "\n",
      "Please answer the following question: The president is the leader of what institution? Choose one of these four options: walmart, white house, country, corporation, government. The correct answer is: corporation.\n",
      "\n",
      "Please answer the following question:\n",
      "Ground truth answer: country\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "generating for i: 4/6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pretty printed output:\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Please answer the following question: What is a great place to lay in the sun? Choose one of these four options: in the basement, west, solar system, beach, beans. The correct answer is: beach.\n",
      "\n",
      "Please answer the following question: What might be the result of a season of successful skiing? Choose one of these four options: finish line, broken bones, broken legs, chapped lips, healthy body. The correct answer is: healthy body.\n",
      "\n",
      "Please answer the following question: She loved buying products, she was driven by her what to shop more than any practical needs? Choose one of these four options: desire, money, time, credit, spending money. The correct answer is: desire.\n",
      "\n",
      "Please answer the following question: What might you feel after doing housework for hours? Choose one of these four options: anger, not boredom, stress, boredom, anxiety. The correct answer is: stress.\n",
      "\n",
      "Please answer the following question: What kind of driving leads to accidents? Choose one of these four options: stressful, dangerous, fun, illegal, deadly. The correct answer is: dangerous.\n",
      "\n",
      "Please answer the following question:\n",
      "Ground truth answer: dangerous\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "generating for i: 5/6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pretty printed output:\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Please answer the following question: What is a great place to lay in the sun? Choose one of these four options: in the basement, west, solar system, beach, beans. The correct answer is: beach.\n",
      "\n",
      "Please answer the following question: What might be the result of a season of successful skiing? Choose one of these four options: finish line, broken bones, broken legs, chapped lips, healthy body. The correct answer is: healthy body.\n",
      "\n",
      "Please answer the following question: She loved buying products, she was driven by her what to shop more than any practical needs? Choose one of these four options: desire, money, time, credit, spending money. The correct answer is: desire.\n",
      "\n",
      "Please answer the following question: What might you feel after doing housework for hours? Choose one of these four options: anger, not boredom, stress, boredom, anxiety. The correct answer is: stress.\n",
      "\n",
      "Please answer the following question: Can you name a good reason for attending school? Choose one of these four options: get smart, boredom, colds and flu, taking tests, spend time. The correct answer is: boredom.\n",
      "\n",
      "Please answer the following question\n",
      "Ground truth answer: \"get smart\"\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "generating for i: 6/6\n",
      "Pretty printed output:\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Please answer the following question: What is a great place to lay in the sun? Choose one of these four options: in the basement, west, solar system, beach, beans. The correct answer is: beach.\n",
      "\n",
      "Please answer the following question: What might be the result of a season of successful skiing? Choose one of these four options: finish line, broken bones, broken legs, chapped lips, healthy body. The correct answer is: healthy body.\n",
      "\n",
      "Please answer the following question: She loved buying products, she was driven by her what to shop more than any practical needs? Choose one of these four options: desire, money, time, credit, spending money. The correct answer is: desire.\n",
      "\n",
      "Please answer the following question: What might you feel after doing housework for hours? Choose one of these four options: anger, not boredom, stress, boredom, anxiety. The correct answer is: stress.\n",
      "\n",
      "Please answer the following question: Stanley had a dream that was very vivid and scary. He had trouble telling it from what? Choose one of these four options: imagination, reality, dreamworker, nightmare, awake. The correct answer is: nightmare.\n",
      "\n",
      "Please answer the following question:\n",
      "Ground truth answer: reality\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(f\"model has #params = {get_num_parameters(model)/10**6:.2f} M\")\n",
    "print(f\"model has size = {get_model_size(model)/MiB:.2f} MiB = {get_model_size(model)/GiB:.2f} GiB\")\n",
    "\n",
    "for idx, (q, c, ans) in enumerate(dataset2):\n",
    "    print(f\"generating for i: {idx+1}/{len(dataset2)}\")\n",
    "    prediction = model.generate(\n",
    "        prepare_input(q, c, qa_prompt_few_shot),\n",
    "        max_new_tokens=10,\n",
    "\n",
    "        do_sample=True,\n",
    "        temperature=0.4,\n",
    "    )\n",
    "    pretty_print(prediction[0])\n",
    "    print(f\"Ground truth answer: {ans}\")\n",
    "    print('\\n\\n\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kvMfRKQyxMwJ"
   },
   "source": [
    "## results and accuracy calculation\n",
    "\n",
    "for clarity, I rewrite only model's responses to the questions:\n",
    "- Please answer the following question: The only baggage the woman checked was a drawstring bag, where was she heading with it? Choose one of these four options: garbage can, military, jewelry store, safe, airport. The correct answer is: jewelry store. (**wrong** as answer: airport)\n",
    "- Please answer the following question: To prevent any glare during the big football game he made sure to clean the dust of his what? Choose one of these four options: television, attic, corner, they cannot clean corner and library during football match they cannot need that, ground. The correct answer is: ground. (**wrong** as answer: television)\n",
    "- Please answer the following question: The president is the leader of what institution? Choose one of these four options: walmart, white house, country, corporation, government. The correct answer is: corporation. (**wrong** as answer: country)\n",
    "- Please answer the following question: What kind of driving leads to accidents? Choose one of these four options: stressful, dangerous, fun, illegal, deadly. The correct answer is: dangerous. (**correct**)\n",
    "- Please answer the following question: Can you name a good reason for attending school? Choose one of these four options: get smart, boredom, colds and flu, taking tests, spend time. The correct answer is: boredom. (**wrong** as answer: \"get smart\")\n",
    "- Please answer the following question: Stanley had a dream that was very vivid and scary. He had trouble telling it from what? Choose one of these four options: imagination, reality, dreamworker, nightmare, awake. The correct answer is: nightmare. (**wrong** as answer: reality)\n",
    "\n",
    "So on the QA task with the few shot prompt, Pythia-1.4B gets $1/6$ correct, accuracy $16.67\\%$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_-aF8Dl8xI0K"
   },
   "source": [
    "## Exercise 3: First neural LM (20 points)\n",
    "\n",
    "Next to reading and understanding package documentations, a key skill for NLP researchers and practitioners is reading and critically assessing NLP literature. The density, but also the style of NLP literature has undergone a significant shift in the recent years with increasing acceleration of progress. Your task in this exercise is to read a paper about one of the first successful neural langauge models, understand its key architectural components and compare how these key components have evolved in modern systems that were discussed in the lecture.\n",
    "\n",
    "> Specifically, please read this paper and answer the following questions: [Bengio et al. (2003)](https://www.jmlr.org/papers/volume3/bengio03a/bengio03a.pdf)\n",
    ">\n",
    "> * How were words / tokens represented? What is the difference / similarity to modern LLMs?\n",
    "\n",
    "Here each unique word as appeared in the training datasets (Brown corpus, AP news) is included in the vocabulary, including punctuations and distinguishing upper and lower cases. Also to reduce the vocabulary size even further, they had only one symbol for all rare words with frequency $\\leq 3$. The vocabulary size was almost $17,000$. They used words as themselves and did not have any tokenizers which are used as a key data preprocessing step in modern LMs.\n",
    "\n",
    "Modern LMs do not always store full words in their vocabulary, instead they store word roots, subwords, suffix-prefix separately etc. These are called _tokens_, and the vocabulary size is large, e.g., $50257$ for GPT2. Storing subword tokens instead of full words can help tokenize a new word (that was not encountered during training) into already known subwords to feed into the network, while Bengio et al.'s model will have to incrementally update the vocabulary in order to accommodate a new word.\n",
    "\n",
    "\n",
    "---\n",
    "> * How was the context represented? What is the difference / similarity to modern LLMs?\n",
    "\n",
    "The context is represented as a sequence of $n-1$ contiguous words to predict the $n$-th word in the Bengio et al. paper. They simply concatenated the word embeddings for the $n-1$ words to prepare the input to the hidden layer. They experimented with $n=5$ or $n=3$ in their _fixed context size_ MLP.\n",
    "\n",
    "In modern LLMs, the maximum context length is very large, e.g., for GPT-2 it was $1024$ tokens (instead of words), and $4096$ tokens for Llama2, and these models also see contexts of varying lengths during training. Also modern LMs DO NOT simply concatenate all the tokens in the input sequence to prepare the context, instead they use the attention mechanism to make the tokens informed about each other to create richer intermediate token representations.\n",
    "\n",
    "---\n",
    "> * What is the curse of dimensionality? Give a concrete example in the context of language modeling.\n",
    "\n",
    "Consider the following domains in increasing dimensions: the interval in $[-1, 1]$ in $\\mathbb{R}$, the square $[-1, 1]^2$ in $\\mathbb{R}^2$, the cube $[-1, 1]^3$ in $\\mathbb{R}^3$ and so on. We observe data samples from this domain in our dataset.\n",
    "The curse of dimensionality essentially says that in high dimensions, to _fill_ the entire space we would need an exponentially high number of data points. In other words, in high dimensions data is extremely sparse and we can always find an empty region of the space (in the domain) where there is no observed data close by, so it is very difficult to generalize.\n",
    "\n",
    "**Language modeling example:** Language models try to predict the conditional distribution of the next word/token given the context, i.e., a sequence of ordered words/tokens, and this probability is represented as $p(w_{n+1}|w_1, w_2, w_3, \\dots w_n)$. Here curse of dimensionality kicks in while trying to capture longer contexts for large values of $n$. For a context size of $n$, to fully specify the conditional probability distribution we would need to specify the distribution $p(w_{n+1}|w_1, \\dots w_n)$ for all possible prefixes ($w_1, w_2, w_3, \\dots w_n$), and the number of such prefixes becomes $|V|^n$ where $V$ is the number of words/tokens in the vocabulary. For large vocabulary size (modern is over ~50k), this is prohibitively expensive to specify the full conditional distribution.\n",
    "\n",
    "But in practice, not all combination of prefixes are likely because of syntactic and semantic restrictions, so this distribution is very sparse, and a good approximation can be obtained by learning such constraints from data.\n",
    "\n",
    "---\n",
    "\n",
    "> * Which training data was used? What is the difference / similarity to modern LLMs?\n",
    "\n",
    "The authors trained their neural language model on two separate text data sources:\n",
    "1. the **Brown corpus** which contains over $1.18M$ words\n",
    "2. and the **Associated Press (AP) News** (a collection of news reports) from 1995 and 1996 consisting of ~ $16M$ words.\n",
    "\n",
    "Both their data sources are fairly limited compared to the current sources of text data for LLMs which is basically the entirety of the Internet. Some examples of modern data sources include: BookCorpus ($800M$ words), and **English Wikipedia ($2500M$ words) that were used to pretrain the BERT encoder and the Colossal Clean Crawled Corpus (about $800$GB of text scraped from internet wth billions of tokens or words) introduced in the T5 paper. So **scale** or size of training data is one obvious difference here, and also Bengio et al. only focused on pretraining while modern LLMs are often customized for various downstream tasks by supervised fine-tuning.\n",
    "\n",
    "---\n",
    "\n",
    "> * Which components of the Bengio et al. (2003) model (if any) can be found in modern LMs?\n",
    "1. the idea of predicting categorical distribution (over the vocabulary) for the next word from a context (sequence of words) --- this is still the main pretraining objective in modern decoder type LMs\n",
    "2. the word embedding look up table (Matrix $C$) is also used in modern LLMs to convert from raw tokens to word embeddings\n",
    "3. the direct connections which is popularly known as skip connections now, and it helps with the vanishing gradients problem in very deep neural networks\n",
    "4. the feedforward network (without the final layer softmax) as a whole is used as one block (FFN) in the Transformer architecture after the attention layer\n",
    "---\n",
    "\n",
    ">\n",
    "> * Please formulate one question about the paper (not the same as the questions above) and post it to the dedicated **Forum** space, and **answer 1 other question** about the paper.\n",
    "\n",
    "My question: [Direct connections vs. skip connections](https://moodle.zdv.uni-tuebingen.de/mod/forum/discuss.php?d=14910)\n",
    "\n",
    "The question I answered: [Data parallel processing](https://moodle.zdv.uni-tuebingen.de/mod/forum/discuss.php?d=14920)\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "Furthermore, your task is to carefully dissect the paper by Bengio et al. (2003) and analyse its structure and style in comparison to another more recent paper:  [Devlin et al. (2019) BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding](https://arxiv.org/pdf/1810.04805)\n",
    "\n",
    "\n",
    "**TASK:**\n",
    "\n",
    "> For each section of the Bengio et al. (2003) paper, what are key differences between the way it is written, the included contents, to the BERT paper (Devlin et al., 2019)? What are key similarities? Write max. 2 sentences per section.\n",
    "\n",
    "\n",
    "**Introduction**\n",
    "\n",
    "\n",
    "Bengio et al. (2003) focuses on introducing a new MLP architecture for language modeling to tackle the curse of dimensionality problem typically encountered by n-gram LMs of that time, and they mainly focus on the language modeling task, i.e., predicting next word from the context.\n",
    "\n",
    "Devlin et al. (2019) focuses on applying language models to various downstream tasks and introduces the BERT architecture, which reduces the need for many task specific architectures as BERT only needs to be finetuned for a wide array of downstream tasks (e.g., NLI, question answering).\n",
    "\n",
    "Both papers introduce a new architecture to tackle problems in natural language processing relevant to their time.\n",
    "\n",
    "\n",
    "**Related Work**\n",
    "\n",
    "Bengio et al. (2003) provided a detailed review of traditional language modeling techniques, such as n-gram models, information retrieval, and papers that also used distributed representations for words in the past, but they did not have a dedicated section for it, and instead kept it as a separate section under Introduction.\n",
    "\n",
    "The BERT paper being more recent discussed more things in the \"Related Work\" section such as advances in unsupervised pretraining of word embeddings (such as GloVe and ELMo) and finetuning approaches (such as GPT2 at that time).\n",
    "\n",
    "Both papers acknowledged the limitations of traditional language modeling approaches and positioned their contributions well in that context.\n",
    "\n",
    "\n",
    "**Model Architecture (A Neural Model + Parallel Implementation in Bengio et al., BERT in Devlin et al.)**\n",
    "\n",
    "Bengio et al. (2003) proposed a neural network architecture with a single hidden layer that uses distributed weight vectors to obtain better generalization (perplexity) compared to n-gram models. This MLP model was trained using the **causal** language modeling objective, i.e., predicting the next word given only _past_ words and they also devoted an entire section to discuss the implementation of their approach as autograd engines (like PyTorch, JAX) were not popular at that time.\n",
    "\n",
    "Devlin et al. (2019) introduced a multi-layer transformer (encoder) architecture with bi-directional attention mechanism. They used two different objectives to pretrain the model:\n",
    "- masked language modeling, where the model can access both past and future tokens in order to predict the word for a certain masked token\n",
    "- next sentence prediction task, to learn better representation for NLI and QA tasks,\n",
    "\n",
    "so BERT is not a causal language model and cannot be used to generate new text on its own.\n",
    "\n",
    "Both papers focus on designing a model that can capture patterns (syntax, semantics etc.) in language data such as next or masked word prediction.\n",
    "\n",
    "\n",
    "**Experiments / Experimental Results**\n",
    "\n",
    "Bengio et al. (2003) evaluated the model on a single language modeling task, while Devlin et al. (2019) evaluated BERT on a wide range of NLP tasks, including question answering, sentiment analysis, and text classification. Also as also noted before, their pre-training dataset sizes were also massively different (max $16M$ words for Bengio et al., whereas $2500M$ tokens for BERT).\n",
    "\n",
    "Both papers emphasize the importance of large-scale training data and computational resources (such as model size).\n",
    "\n",
    "\n",
    "\n",
    "**Extensions and Future Work / Ablation Studies**\n",
    "\n",
    "Here Bengio et al. discussed different ways to improve on the MLP model such as incorporating out of vocabulary words, tricks to reduce computation complexity etc.\n",
    "\n",
    "The BERT paper had a separate section after the experiments for ablation studies to validate the design choices (such as pretraining losses, model sizes etc.) that they made in the experiments.\n",
    "\n",
    "\n",
    "**Conclusion**\n",
    "\n",
    "Bengio et al. (2003) concludes by highlighting the potential of neural networks for language modeling as another statistical model of language, while Devlin et al. (2019) concludes by demonstrating the effectiveness of pre-trained language models for a wide range of downstream, or even low resource NLP tasks.\n",
    "\n",
    "Both papers highlight their major contribution and stress again on its potential applications in NLP.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Ys9QcuQzxI0L"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fECAXooyxI0L"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GMQoDOu6xI0L"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Q-fH8FlexI0L"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "0024448720c24de981df36b5b36b6b02": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "030d3b89b1a6437f88c2828610222028": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "05bf0a28c84a4c408e29f46db5c34d27": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_0024448720c24de981df36b5b36b6b02",
      "max": 396,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_acc6cb9cde0c48d7a3625f11a519a187",
      "value": 396
     }
    },
    "0d1596ac5ff04df899c5c73dce953796": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "23cecadb1aca40b291112fd10502ddb7": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "2767a8a66763411caa4e091725ab784f": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "28764f61414e4af3949b1506aab1e850": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_4324d53817df4253b310d5cb2c13a3ae",
       "IPY_MODEL_88de360dfd4d4027b25fde35d986e508",
       "IPY_MODEL_7b53c1e5c8994c9794dbe4de01cb3bbf"
      ],
      "layout": "IPY_MODEL_23cecadb1aca40b291112fd10502ddb7"
     }
    },
    "28a5a9475c6a46a4b96df96bfeef4f4f": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "29954e292761402389646eeb530af315": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "2b5201b0436044d9a660d12253498c77": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "2c95d6fe0af04873be673e1b981d201d": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "30dcbaa35d66460da9c5d99787a478de": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_4e5965f7ae42492fac9aa2b653199b58",
       "IPY_MODEL_89e8baa7a16940c5a18e903ecef82020",
       "IPY_MODEL_a04048dc9dbc431eb5b87f462a7eb8bd"
      ],
      "layout": "IPY_MODEL_47d464339753493fb2e274dce3b88368"
     }
    },
    "37336632630b437cb0feb30f5e19cc9f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_29954e292761402389646eeb530af315",
      "placeholder": "​",
      "style": "IPY_MODEL_fc88234ce5124bccab1517331aeb2a2d",
      "value": "tokenizer.json: 100%"
     }
    },
    "38259baaed4042f58df7fa9709eac42f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_2b5201b0436044d9a660d12253498c77",
      "placeholder": "​",
      "style": "IPY_MODEL_b5a92ee07e1d4468a0fab1ddda974404",
      "value": "config.json: 100%"
     }
    },
    "3d19c1f02f1c4ed5b6a8fe7c97baf11f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "3d7a4af6d2f8400482d3db15fb1bcba1": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_5c2f751f4b224dcb8671e786cf721dbc",
      "max": 570,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_94712a9fb31c4a1481d090a17c736a4d",
      "value": 570
     }
    },
    "4324d53817df4253b310d5cb2c13a3ae": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_c8979dfc77ea455dbc5feababc45089e",
      "placeholder": "​",
      "style": "IPY_MODEL_b11d03c1c3024dd0ad1d5e04e21e0de1",
      "value": "special_tokens_map.json: 100%"
     }
    },
    "47d464339753493fb2e274dce3b88368": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "4e5965f7ae42492fac9aa2b653199b58": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_8641b5c946dd44c6974c8bd1e3396710",
      "placeholder": "​",
      "style": "IPY_MODEL_743320a97e1c4516ba27f4ef7ed8314e",
      "value": "model.safetensors: 100%"
     }
    },
    "4f4768358f4c43d289d1ff6e907b9a49": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "5c2f751f4b224dcb8671e786cf721dbc": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "6308fc726ac04ab6a75355a2bbbb13b0": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "688cbf78b1b54477a8eb838857274bf9": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_a97910162a4f4a5496e1d90b8c4e4597",
      "placeholder": "​",
      "style": "IPY_MODEL_dafb02b0e0c54e7ca821214294c07361",
      "value": "tokenizer_config.json: 100%"
     }
    },
    "6f735657edca43398b81e8c9d890456a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_37336632630b437cb0feb30f5e19cc9f",
       "IPY_MODEL_79e34d4d3e13459f8e45f7195b2f6fdd",
       "IPY_MODEL_882b993f9a5643ca88bd7ad1e1989ccd"
      ],
      "layout": "IPY_MODEL_d77fb48c43d845a98d6f6a1adcaee2af"
     }
    },
    "743320a97e1c4516ba27f4ef7ed8314e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "79e34d4d3e13459f8e45f7195b2f6fdd": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_28a5a9475c6a46a4b96df96bfeef4f4f",
      "max": 2113710,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_e6a894b83744426a9a7e775f9c28b87b",
      "value": 2113710
     }
    },
    "7b53c1e5c8994c9794dbe4de01cb3bbf": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_a2ffe451540c480c8da8a3a7b742c187",
      "placeholder": "​",
      "style": "IPY_MODEL_f15700a62d7f4d32982e562f5102e4d4",
      "value": " 99.0/99.0 [00:00&lt;00:00, 3.30kB/s]"
     }
    },
    "8641b5c946dd44c6974c8bd1e3396710": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "882b993f9a5643ca88bd7ad1e1989ccd": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_2c95d6fe0af04873be673e1b981d201d",
      "placeholder": "​",
      "style": "IPY_MODEL_0d1596ac5ff04df899c5c73dce953796",
      "value": " 2.11M/2.11M [00:00&lt;00:00, 9.83MB/s]"
     }
    },
    "88de360dfd4d4027b25fde35d986e508": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_030d3b89b1a6437f88c2828610222028",
      "max": 99,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_dca9bd6f8a0144d3be5ef1edea540b3d",
      "value": 99
     }
    },
    "89e8baa7a16940c5a18e903ecef82020": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_6308fc726ac04ab6a75355a2bbbb13b0",
      "max": 2930002184,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_3d19c1f02f1c4ed5b6a8fe7c97baf11f",
      "value": 2930002184
     }
    },
    "8cdd3c5c44b24b27aeab6efb6445925b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "94712a9fb31c4a1481d090a17c736a4d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "962871510b174289bddb3900d5e747bb": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "99304db5d8de41d6bca696316c434c13": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "9e3c672f09ab441d91f3ee317dca2d1d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "a04048dc9dbc431eb5b87f462a7eb8bd": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_bfe93d9024d04e38a11c71ac5f06512e",
      "placeholder": "​",
      "style": "IPY_MODEL_8cdd3c5c44b24b27aeab6efb6445925b",
      "value": " 2.93G/2.93G [00:29&lt;00:00, 177MB/s]"
     }
    },
    "a2d27d835c3049eb8c76a341075d6385": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_99304db5d8de41d6bca696316c434c13",
      "placeholder": "​",
      "style": "IPY_MODEL_962871510b174289bddb3900d5e747bb",
      "value": " 570/570 [00:00&lt;00:00, 19.3kB/s]"
     }
    },
    "a2ffe451540c480c8da8a3a7b742c187": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "a97910162a4f4a5496e1d90b8c4e4597": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "aa7d30d58ad849bcb9028f3f320847cc": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_38259baaed4042f58df7fa9709eac42f",
       "IPY_MODEL_3d7a4af6d2f8400482d3db15fb1bcba1",
       "IPY_MODEL_a2d27d835c3049eb8c76a341075d6385"
      ],
      "layout": "IPY_MODEL_2767a8a66763411caa4e091725ab784f"
     }
    },
    "ab8c7ae66f8e49bf822aa3a1014dbe7f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_4f4768358f4c43d289d1ff6e907b9a49",
      "placeholder": "​",
      "style": "IPY_MODEL_9e3c672f09ab441d91f3ee317dca2d1d",
      "value": " 396/396 [00:00&lt;00:00, 26.0kB/s]"
     }
    },
    "acc6cb9cde0c48d7a3625f11a519a187": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "b11d03c1c3024dd0ad1d5e04e21e0de1": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "b5a92ee07e1d4468a0fab1ddda974404": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "b9f1b1dacebb479dad091c876a706fc0": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_688cbf78b1b54477a8eb838857274bf9",
       "IPY_MODEL_05bf0a28c84a4c408e29f46db5c34d27",
       "IPY_MODEL_ab8c7ae66f8e49bf822aa3a1014dbe7f"
      ],
      "layout": "IPY_MODEL_e0fed210c6ee4bbca6ef9a82dd82495e"
     }
    },
    "bfe93d9024d04e38a11c71ac5f06512e": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "c8979dfc77ea455dbc5feababc45089e": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "d77fb48c43d845a98d6f6a1adcaee2af": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "dafb02b0e0c54e7ca821214294c07361": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "dca9bd6f8a0144d3be5ef1edea540b3d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "e0fed210c6ee4bbca6ef9a82dd82495e": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "e6a894b83744426a9a7e775f9c28b87b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "f15700a62d7f4d32982e562f5102e4d4": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "fc88234ce5124bccab1517331aeb2a2d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
