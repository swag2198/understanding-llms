{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Homework 1: Language models (50 points)\n",
    "\n",
    "The first homework focuses on the following skills: being able to work with simple formal exercises on language modeling, on understanding and being able to extract properties and configurations of state-of-the-art language models and, finally, training language models yourself!\n",
    "\n",
    "### Logistics\n",
    "\n",
    "* submission deadline: May 15th 23:59 German time via Moodle\n",
    "  * please upload a **SINGLE ZIP FILE named Surname_FirstName_HW1.zip** containing the .ipynb file of the notebook (if you solve it on Colab, you can go to File > download), the json file for Ex. 2 and a .png or .jpg file with your losses plot from Ex. 3.\n",
    "* please solve and submit the homework **individually**! \n",
    "* if you use Colab, to speed up the execution of the code on Colab (especially Exercise 3), you can use the available GPU (if Colab resources allow). For that, before executing your code, navigate to Runtime > Change runtime type > GPU > Save."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 1: Understanding language modeling (12 points)\n",
    "\n",
    "Please answer the following exercises. Importantly, please reason step by step; i.e., where calculations are required, please provide intermediate steps of how you arrived at your solution. You do not need to write any code, just mathematical solutions.\n",
    "\n",
    "> 1. [6pts] Consider the corpus $C$ with the following sentences: $C=${\"The cat sleeps\", \"The mouse sings\", \"The cat sleeps\", \"A dog sings\"}. \n",
    "> (a) Define the vocabulary $V$ of this corpus (assuming by-word tokenization).\n",
    "> (b) Pick one of the four sentences in $C$. Formulate the probability of that sentence in the form of the chain rule. Calculate the probability of each termn in the chain rule, given the corpus.\n",
    "> 2. [4pts] We want to train a neural network that takes as input two numbers $x_1, x_2$, passes them through three hidden linear layers, each with 13 neurons, each followed by the ReLU activation function, and outputs three numbers $y_1, y_2, y_3$. Write down all weight matrices of this network with their dimensions. (Example: if one weight matrix has the dimensions 3x5, write $M_1\\in R^{3\\times5}$) \n",
    "> 3. [2pts] Consider the sequence: \"Input: Some students trained each language model\". Assuming that each word+space/punctuation corresponds to one token, consider the following token probabilities of this sequence under some trained language model: $p = [0.67, 0.91, 0.83, 0.40, 0.29, 0.58, 0.75]$. Compute the average surprisal of this sequence under that language model. [Note: in this class we always assume the base $e$ for $log$, unless indicated otherwise. This is also usually the case throughout NLP.]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "**1.**\n",
    "\n",
    "**a**. Assuming *by-word* tokenization (individual words as tokens), we have the following vocabulary:\n",
    "$$ \n",
    "V = \\{the, \\; cat, \\;sleeps, \\;mouse, \\;sings, \\;a, \\;dog\\},\n",
    "$$\n",
    "so the total no. of unique words in the vocabulary $=|V|=7$.\n",
    "\n",
    "**b**. Taking the sentence: \"The cat sleeps\", its probability can be computed as:\n",
    "$$\n",
    "p(the \\;cat \\;sleeps) = p(the) \\times p(cat \\;|\\; the) \\times p(sleeps \\;|\\; the \\;cat)\n",
    "$$\n",
    "\n",
    "To calculate each of these (conditional) probabilities, we need to inspect the corresponding frequencies (or words, word pairs, or word triplets) in the corpus. For individual words, we compute the frequencies of each word in the corpus, and that gives:\n",
    "```\n",
    "{the: 3, cat: 2, sleeps: 2, mouse: 1, sings: 2, a: 1, dog: 1}\n",
    "```\n",
    "hence $p(the) = \\frac{3}{12}$.\n",
    "\n",
    "For bigram probabilities, we need to compute a table that gives the $Count(w_{i+1}|w_i)$, i.e., how many times in the corpus the word $w_{i+1}$ has followed the word $w_i$, and we can normalize each row to get the corresponding probabilities.\n",
    "\n",
    "{\"The cat sleeps\", \"The mouse sings\", \"The cat sleeps\", \"A dog sings\"}\n",
    "\n",
    "| $w_{i+1}$ $\\rightarrow$ |  the | cat | sleeps | mouse | sings | a | dog |\n",
    "| :---        |    :----:   | :---: | :---: |:---: | :---: | :---: | :---: |\n",
    "| $w_i=$the      | 0 | 2 | 0 | 1 | 0 | 0 | 0 |\n",
    "| $w_i=$cat      | 0 | 0 | 2 | 0 | 0 | 0 | 0 |\n",
    "| $w_i=$sleeps      | 0 | 0 | 0 | 0 | 0 | 0 | 0 |\n",
    "| $w_i=$mouse      | 0 | 0 | 0 | 0 | 1 | 0 | 0 |\n",
    "| $w_i=$sings      | 0 | 0 | 0 | 0 | 0 | 0 | 0 |\n",
    "| $w_i=$a      | 0 | 0 | 0 | 0 | 0 | 0 | 1 |\n",
    "| $w_i=$dog      | 0 | 0 | 0 | 0 | 1 | 0 | 0 |\n",
    "\n",
    "From this table, $p(cat \\;|\\; the) = \\frac{2}{3}$. This can also be computed using the count formula directly:\n",
    "$$\n",
    "p(cat \\;|\\; the) = \\frac{Count(the \\; cat \\; sleeps)}{Count(the)} = \\frac{2}{3}.\n",
    "$$\n",
    "\n",
    "Similarly, we can construct a table of size ${7 \\choose 2} 2!$ x $7$ = $42$ x $7$ with all possible two-word prefixes to predict the third word. This table will be mostly sparse. We can simply compute $p(sleeps \\;|\\; the \\;cat)$ using the count formula:\n",
    "$$\n",
    "p(sleeps \\;|\\; the \\;cat) = \\frac{Count(the \\; cat \\; sleeps)}{Count(the \\; cat)} = \\frac{2}{2} = 1.\n",
    "$$\n",
    "\n",
    "Final probability:\n",
    "$$\n",
    "p(the \\;cat \\;sleeps) = p(the) \\times p(cat \\;|\\; the) \\times p(sleeps \\;|\\; the \\;cat) = \\frac{3}{12} \\times \\frac{2}{3} \\times 1 = \\frac{1}{6}.\n",
    "$$\n",
    "\n",
    "---\n",
    "\n",
    "**2.**\n",
    "\n",
    "The shapes of vectors in the neural network: `2 (input) --> 13 (h1) --> 13 (h2) --> 13 (h3) --> 3 (output)`. So there are four linear layers/weight matrices in the network, and assuming the input to the network having shape `[N, 2]` where `N` is the batch dimension, the matrices have dimensions: $M_1\\in \\mathbb{R}^{2\\times13}$, $M_2\\in \\mathbb{R}^{13\\times13}$, $M_3\\in \\mathbb{R}^{13\\times13}$ and $M_4\\in \\mathbb{R}^{13\\times3}$.\n",
    "\n",
    "---\n",
    "**3.**\n",
    "The following probabilities are given (assuming beginning and end of sentence tokens):\n",
    "- p(some | `<bos>`) = $0.67$\n",
    "- p(students | some) = $0.91$\n",
    "- p(trained | some students) = $0.83$\n",
    "- p(each | some students trained) = $0.40$\n",
    "- p(language | some students trained each) = $0.29$\n",
    "- p(model | some students trained each language) = $0.58$\n",
    "- p(`<eos>` | some students trained each language model) = $0.75$\n",
    "\n",
    "$P_{LM}(some, \\;students, \\;trained, \\;each, \\;language, \\;model, .) = p(some | \\langle bos \\rangle) \\times \\dots \\times p(\\langle eos \\rangle | some, \\;students, \\;trained, \\;each, \\;language, \\;model)$\n",
    "\n",
    "and average surprisal of the given sequence $=-\\frac{1}{7}\\;\\log P_{LM}\\;(some, students, trained, each, language, model, .) \\approx 0.523956.  $\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5239560604095459"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p = torch.tensor([0.67, 0.91, 0.83, 0.40, 0.29, 0.58, 0.75])\n",
    "surprisal = -p.log().sum() / len(p)\n",
    "surprisal.item()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 2: Extracting LLM fingerprints (15 points)\n",
    "\n",
    "For this task, your job is to extract the \"fingerprint\" of a state-of-the-art large language model from the paper. Specifically, you job is to: \n",
    "* find the model that is assigned to your surname in the list **HW1_Model2Group_assignment.csv** (to be found on Moodle under topic 02). Please investigate the latest version of your model, unless the version is specified in the list.\n",
    "* find out the following charactersitcs of your model \n",
    "* submit a json file with your responses in the following format (below is a partial example). \n",
    " \n",
    "Note that, of course, it might be that some information is not available or that some categories are not applicable. The idea is, that, as a course we can create a fun website which will show a somewhat comprehensive graphical comparison of current language models and their configurations. Based on your collective json files, the lecturers will set up a front end at some point during the class.\n",
    "\n",
    "**IMPORTANT**: Please email the lecturers by the homework deadline if you DO NOT consent that your json file is used for this idea."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'model_name': 'Microsoft Phi-2',\n",
       " 'huggingface_model_id': 'microsoft/phi-2',\n",
       " 'paper_url': 'https://www.microsoft.com/en-us/research/blog/phi-2-the-surprising-power-of-small-language-models/',\n",
       " 'tokenizer_type': 'BPE (CodeGen Tokenizer)',\n",
       " 'vocabulary_size': '51200',\n",
       " 'architecture': 'transformer stack with causal language modeling head',\n",
       " 'architecture_type': 'decoder only',\n",
       " 'architecture_quirks': ['vocab size discrepancy - it has embedding size as 51200 to accommodate any new tokens',\n",
       "  'can choose/configure among three attention classes - regular attention, flash attention, and scaled dot product attention',\n",
       "  'has attention overflow issue with FP16, requires enabling/disabling autocast on PhiAttention.forward() function'],\n",
       " 'parameters': '2.7B',\n",
       " 'finetuning_type': 'not finetuned',\n",
       " 'training_data_cutoff': '2023',\n",
       " 'number_training_tokens': '1.4T tokens',\n",
       " 'pretraining_data_size': '250B tokens',\n",
       " 'finetuning_data_size': 'NA',\n",
       " 'training_data': ['python codes from The Stack v1.2',\n",
       "  'q&a content from StackOverflow',\n",
       "  'google-deepmind code_contests dataset',\n",
       "  'synthetic python textbooks and exercises generated by gpt-3.5-turbo-0301',\n",
       "  'various NLP synthetic texts',\n",
       "  'filtered websites (Falcon RefinedWeb and SlimPajama assessed by gpt-4) for safety and educational value'],\n",
       " 'finetuning_data': [],\n",
       " 'access': 'open',\n",
       " 'summary': 'Phi-2 is a relatively smaller language model (only 2.7B params), but it surpasses or matches performances of models upto 25x larger (Mistral (7B) or Llama-2 (13B) models) on coding and math tasks. It was neither further finetuned with RLHF, nor instruction fine-tuned, so its generation capability is non-restricted, and because of its compact size, researchers can use it to explore safety, fairness and bias related challenges in LMs.'}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "phi2 = {\n",
    "    \"model_name\": \"Microsoft Phi-2\",\n",
    "    \"huggingface_model_id\": \"microsoft/phi-2\",\n",
    "    \"paper_url\": \"https://www.microsoft.com/en-us/research/blog/phi-2-the-surprising-power-of-small-language-models/\",\n",
    "    \"tokenizer_type\": \"BPE (CodeGen Tokenizer)\",\n",
    "    \"vocabulary_size\": \"51200\", # vocab size discrepancy: https://huggingface.co/microsoft/phi-2/discussions/97\n",
    "    \"architecture\": \"transformer stack with causal language modeling head\",\n",
    "    \"architecture_type\": \"decoder only\",\n",
    "    \"architecture_quirks\": [\n",
    "        \"vocab size discrepancy - it has embedding size as 51200 to accommodate any new tokens\",\n",
    "        \"can choose/configure among three attention classes - regular attention, flash attention, and scaled dot product attention\",\n",
    "        \"has attention overflow issue with FP16, requires enabling/disabling autocast on PhiAttention.forward() function\",\n",
    "    ],\n",
    "    \"parameters\": \"2.7B\",\n",
    "    \"finetuning_type\": \"not finetuned\",\n",
    "    \"training_data_cutoff\": \"2023\", # time of release \n",
    "    \"number_training_tokens\": \"1.4T tokens\",\n",
    "    \"pretraining_data_size\": \"250B tokens\",\n",
    "    \"finetuning_data_size\": \"NA\",\n",
    "    \"training_data\": [\n",
    "        \"python codes from The Stack v1.2\",\n",
    "        \"q&a content from StackOverflow\",\n",
    "        \"google-deepmind code_contests dataset\",\n",
    "        \"synthetic python textbooks and exercises generated by gpt-3.5-turbo-0301\",\n",
    "        \"various NLP synthetic texts\",\n",
    "        \"filtered websites (Falcon RefinedWeb and SlimPajama assessed by gpt-4) for safety and educational value\",\n",
    "    ],\n",
    "    \"finetuning_data\": [],\n",
    "    \"access\": \"open\",\n",
    "    \"summary\": \"Phi-2 is a relatively smaller language model (only 2.7B params), but it surpasses or matches performances of models upto 25x larger (Mistral (7B) or Llama-2 (13B) models) on coding and math tasks. It was neither further finetuned with RLHF, nor instruction fine-tuned, so its generation capability is non-restricted, and because of its compact size, researchers can use it to explore safety, fairness and bias related challenges in LMs.\"\n",
    "}\n",
    "phi2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "with open('ex2_phi2model.json', 'w') as fp:\n",
    "    json.dump(phi2, fp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 3: Fine-tuning GPT-2 for QA (23 points)\n",
    "\n",
    "The learning goal of this exercise is to practice fine-tuning a pretrained LM, GPT-2 small, for a particular task, namely commonsense question answering (QA). We will use a task-specific dataset, [CommonsenseQA](https://huggingface.co/datasets/tau/commonsense_qa), that was introduced by [Talmor et al. (2018)](https://arxiv.org/abs/1811.00937). We will evaluate the performance of the model on our test split of the dataset over training to monitor whether the model's performance is improving and compare the performance of the base pretrained GPT-2 and the fine-tuned model. We will need to perform the following steps: \n",
    "\n",
    "1. Prepare data according to steps described in [sheet 1.1](https://cogsciprag.github.io/Understanding-LLMs-course/tutorials/01-introduction.html#main-training-data-processing-steps)\n",
    "   1. additionally to these steps, prepare a custom Dataset (like in [sheet 2.3](https://cogsciprag.github.io/Understanding-LLMs-course/tutorials/02c-MLP-pytorch.html#preparing-the-training-data)) that massages the dataset from the format that it is shipped in on HuggingFace into strings that can be used for training. Some of the procesing steps will happen in the Dataset.\n",
    "2. Load the pretrained GPT-2 model\n",
    "3. Set up training pipeline according to steps described in [sheet 2.5]()\n",
    "4. Run the training while tracking the losses\n",
    "5. Save plot of losses for submission"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Your tasks:\n",
    "> 1. [19pts] Complete the code in the spots where there is a comment \"#### YOUR CODE HERE ####\". There are instructions in the comments as to what the code should implement. With you completed code, you should be able to let the training run without errors. Note that the point of the exercise is the implementation; we should not necessarily expect great performance of the fine-tuned model (and the actual performance will *not* be graded). Often there are several correct ways of implementing something. Anything that is correct will be accepted.\n",
    "> 2. [4pts] Answer questions at the end of the execise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/swagatam/miniconda3/envs/ullm/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# note: if you are on Colab, you might need to install some requirements\n",
    "# as we did in Sheet 1.1. Otherwise, don't forget to activate your local environment\n",
    "\n",
    "from datasets import load_dataset\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, GPT2Tokenizer, GPT2LMHeadModel\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import Dataset\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# additioanlly, we need to install accelerate\n",
    "# uncomment and run the following line on Colab or in your environment\n",
    "# !pip install accelerate\n",
    "# NOTE: in a notebook, reloading of the kernel might be required after installation if you get dependency errors with the transformers package"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "### 1. Prepare data with data prepping steps from sheet 1.1\n",
    "\n",
    "# a. Acquiring data\n",
    "# b. (minimally) exploring dataset\n",
    "# c. cleaning / wrangling data (combines step 4 from sheet 1.1 and step 1.1 above)\n",
    "# d. splitting data into training and test set (we will not do any hyperparam tuning) \n",
    "# (we don't need further training set wrangling)\n",
    "# e. tokenizing data and making sure it can be batched (i.e., conversted into 2d tensors)\n",
    "# this will also happen in our custom Dataset class (common practice when working with text data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# downaload dataset from HF\n",
    "dataset = load_dataset(\"tau/commonsense_qa\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['train', 'validation', 'test'])\n",
      "\n",
      "one sample from train split \n",
      "---\n",
      " {'id': '075e483d21c29a511267ef62bedc0461', 'question': 'The sanctions against the school were a punishing blow, and they seemed to what the efforts the school had made to change?', 'question_concept': 'punishing', 'choices': {'label': ['A', 'B', 'C', 'D', 'E'], 'text': ['ignore', 'enforce', 'authoritarian', 'yell at', 'avoid']}, 'answerKey': 'A'}\n",
      "\n",
      "one sample from validation split \n",
      "---\n",
      " {'id': '1afa02df02c908a558b4036e80242fac', 'question': 'A revolving door is convenient for two direction travel, but it also serves as a security measure at a what?', 'question_concept': 'revolving door', 'choices': {'label': ['A', 'B', 'C', 'D', 'E'], 'text': ['bank', 'library', 'department store', 'mall', 'new york']}, 'answerKey': 'A'}\n",
      "\n",
      "one sample from the test split \n",
      "---\n",
      " {'id': '90b30172e645ff91f7171a048582eb8b', 'question': 'The townhouse was a hard sell for the realtor, it was right next to a high rise what?', 'question_concept': 'townhouse', 'choices': {'label': ['A', 'B', 'C', 'D', 'E'], 'text': ['suburban development', 'apartment building', 'bus stop', 'michigan', 'suburbs']}, 'answerKey': ''}\n"
     ]
    }
   ],
   "source": [
    "# inspect dataset\n",
    "print(dataset.keys())\n",
    "# print a sample from the dataset\n",
    "### YOUR CODE HERE ####\n",
    "print(f'\\none sample from train split \\n---\\n {dataset[\"train\"][0]}\\n')\n",
    "print(f'one sample from validation split \\n---\\n {dataset[\"validation\"][0]}\\n')\n",
    "print(f'one sample from the test split \\n---\\n {dataset[\"test\"][0]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that the test split does not have ground truth answer labels. Therefore, **we will use the validation split as our test split**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"gpt2\")\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "# set padding side to be left because we are doing causal LM\n",
    "tokenizer.padding_side = \"left\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def massage_input_text(example):\n",
    "    \"\"\"\n",
    "    Helper for converting input examples which have \n",
    "    a separate qquestion, labels, answer options\n",
    "    into a single string.\n",
    "\n",
    "    Arguments\n",
    "    ---------\n",
    "    example: dict\n",
    "        Sample input from the dataset which contains the \n",
    "        question, answer labels (e.g. A, B, C, D),\n",
    "        the answer options for the question, and which \n",
    "        of the answers is correct.\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    input_text: str\n",
    "        Formatted training text which contains the question,\n",
    "        the forwatted answer options (e.g., 'A. <option 1> B. <option 2>' etc)\n",
    "        and the ground truth answer.\n",
    "    \"\"\"\n",
    "    # combine each label with its corresponding text\n",
    "    answer_options_list = list(zip(\n",
    "        example[\"choices\"][\"label\"],\n",
    "        example[\"choices\"][\"text\"]\n",
    "    ))\n",
    "    # join each label and text with . and space\n",
    "    answer_options = ['. '.join(y) for y in answer_options_list] ### YOUR CODE HERE ####\n",
    "    # join the list of options with spaces into single string\n",
    "    answer_options_string = ' '.join(answer_options) ### YOUR CODE HERE ####\n",
    "    # combine question and answer options\n",
    "    input_text = example[\"question\"] + \" \" + answer_options_string\n",
    "    # append the true answer with a new line, \"Answer: \" and the label\n",
    "    input_text += \"\\nAnswer: \" + example[\"answerKey\"]\n",
    "\n",
    "    return input_text\n",
    "\n",
    "# process input texts of train and test sets\n",
    "massaged_datasets = dataset.map(\n",
    "    lambda example: {\n",
    "        \"text\": massage_input_text(example)\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': '075e483d21c29a511267ef62bedc0461',\n",
       " 'question': 'The sanctions against the school were a punishing blow, and they seemed to what the efforts the school had made to change?',\n",
       " 'question_concept': 'punishing',\n",
       " 'choices': {'label': ['A', 'B', 'C', 'D', 'E'],\n",
       "  'text': ['ignore', 'enforce', 'authoritarian', 'yell at', 'avoid']},\n",
       " 'answerKey': 'A',\n",
       " 'text': 'The sanctions against the school were a punishing blow, and they seemed to what the efforts the school had made to change? A. ignore B. enforce C. authoritarian D. yell at E. avoid\\nAnswer: A'}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# inspect a sample from our preprocessed data\n",
    "massaged_datasets[\"train\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'id': '1afa02df02c908a558b4036e80242fac',\n",
       "  'question': 'A revolving door is convenient for two direction travel, but it also serves as a security measure at a what?',\n",
       "  'question_concept': 'revolving door',\n",
       "  'choices': {'label': ['A', 'B', 'C', 'D', 'E'],\n",
       "   'text': ['bank', 'library', 'department store', 'mall', 'new york']},\n",
       "  'answerKey': 'A',\n",
       "  'text': 'A revolving door is convenient for two direction travel, but it also serves as a security measure at a what? A. bank B. library C. department store D. mall E. new york\\nAnswer: A'},\n",
       " {'id': '90b30172e645ff91f7171a048582eb8b',\n",
       "  'question': 'The townhouse was a hard sell for the realtor, it was right next to a high rise what?',\n",
       "  'question_concept': 'townhouse',\n",
       "  'choices': {'label': ['A', 'B', 'C', 'D', 'E'],\n",
       "   'text': ['suburban development',\n",
       "    'apartment building',\n",
       "    'bus stop',\n",
       "    'michigan',\n",
       "    'suburbs']},\n",
       "  'answerKey': '',\n",
       "  'text': 'The townhouse was a hard sell for the realtor, it was right next to a high rise what? A. suburban development B. apartment building C. bus stop D. michigan E. suburbs\\nAnswer: '})"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "massaged_datasets[\"validation\"][0], massaged_datasets[\"test\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CommonsenseQADataset(Dataset):\n",
    "    \"\"\"\n",
    "    Custom dataset class for CommonsenseQA dataset.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "            self, \n",
    "            train_split, \n",
    "            test_split,\n",
    "            tokenizer,\n",
    "            max_length=64,\n",
    "            dataset_split=\"train\",\n",
    "        ) -> None:\n",
    "        \"\"\"\n",
    "        Initialize the dataset object.\n",
    "        \n",
    "        Arguments\n",
    "        ---------\n",
    "        train_split: dict\n",
    "            Training data dictionary with different columns.\n",
    "        test_split: dict\n",
    "            Test data dictionary with different columns.\n",
    "        tokenizer: Tokenizer\n",
    "            Initialized tokenizer for processing samples.\n",
    "        max_length: int\n",
    "            Maximal length of inputs. All inputs will be \n",
    "            truncated or padded to this length.\n",
    "        dataset_split: str\n",
    "            Specifies which split of the dataset to use. \n",
    "            Default is \"train\".\n",
    "        \"\"\"\n",
    "        self.train_split = train_split['text']\n",
    "        self.test_split = test_split['text']\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_length = max_length\n",
    "        self.dataset_split = dataset_split\n",
    "\n",
    "    def __len__(self):\n",
    "        \"\"\"\n",
    "        Method returning the length of the training dataset.\n",
    "        \"\"\"\n",
    "        \n",
    "        if self.dataset_split == \"train\":\n",
    "            return len(self.train_split) ### YOUR CODE HERE ####\n",
    "        return len(self.test_split)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        \"\"\"\n",
    "        Method returning a single training example.\n",
    "        Note that it also tokenizes, truncates or pads the input text.\n",
    "        Further, it creates a mask tensor for the input text which \n",
    "        is used for causal masking in the transformer model.\n",
    "\n",
    "        Arguments\n",
    "        ---------\n",
    "        idx: int\n",
    "            Index of training sample to be retrieved from the data.\n",
    "        \n",
    "        Returns\n",
    "        --------\n",
    "        tokenized_input: dict\n",
    "            Dictionary with input_ids (torch.Tensor) and an attention_mask\n",
    "            (torch.Tensor).\n",
    "        \"\"\"\n",
    "        # retrieve a training sample at the specified index idx\n",
    "        # HINT: note that this might depend on self.dataset_split\n",
    "        if self.dataset_split == \"train\":\n",
    "            input_text = self.train_split[idx]\n",
    "        elif self.dataset_split == \"test\":\n",
    "            input_text = self.test_split[idx] ### YOUR CODE HERE ####\n",
    "        \n",
    "        tokenized_input = self.tokenizer(\n",
    "            input_text,\n",
    "            max_length=self.max_length, ### YOUR CODE HERE ####\n",
    "            padding=\"max_length\",\n",
    "            truncation=True,\n",
    "            return_tensors=\"pt\"\n",
    "        )\n",
    "        tokenized_input[\"attention_mask\"] = (tokenized_input[\"input_ids\"] != tokenizer.pad_token_id).long()\n",
    "        return tokenized_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: mps\n"
     ]
    }
   ],
   "source": [
    "# move to accelerated device \n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "    print(f\"Device: {device}\")\n",
    "elif torch.backends.mps.is_available():\n",
    "    device = torch.device(\"mps\")\n",
    "    print(f\"Device: {device}\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "    print(f\"Device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPT-2 size: 124.4M parameters\n"
     ]
    }
   ],
   "source": [
    "# 2. init model\n",
    "\n",
    "# load pretrained gpt2 for HF\n",
    "model = GPT2LMHeadModel.from_pretrained(\"gpt2\").to(device) ### YOUR CODE HERE ####\n",
    "# print num of trainable parameters\n",
    "model_size = sum(t.numel() for t in model.parameters())\n",
    "print(f\"GPT-2 size: {model_size/1000**2:.1f}M parameters\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hint: If you run out of memory while trying to run the training, try decreasing the batch size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. set up configurations required for the training loop\n",
    "\n",
    "# instantiate dataset with the downloaded commonsense_qa data \n",
    "train_dataset = CommonsenseQADataset(\n",
    "    ### YOUR CODE HERE ####\n",
    "    massaged_datasets[\"train\"],\n",
    "    massaged_datasets[\"validation\"],\n",
    "    tokenizer,\n",
    ")\n",
    "# instantiate test dataset with the downloaded commonsense_qa data\n",
    "test_dataset = CommonsenseQADataset(\n",
    "    ### YOUR CODE HERE ####,\n",
    "    massaged_datasets[\"train\"],\n",
    "    massaged_datasets[\"validation\"],\n",
    "    tokenizer,\n",
    "    dataset_split=\"test\"\n",
    ")\n",
    "# create a DataLoader for the dataset\n",
    "# the data loader will automatically batch the data\n",
    "# and iteratively return training examples (question answer pairs) in batches\n",
    "dataloader = DataLoader(\n",
    "    train_dataset, \n",
    "    batch_size=32, \n",
    "    shuffle=True\n",
    ")\n",
    "# create a DataLoader for the test dataset\n",
    "# reason for separate data loader is that we want to\n",
    "# be able to use a different index for retreiving the test batches\n",
    "# we might also want to use a different batch size etc.\n",
    "test_dataloader = DataLoader(\n",
    "    test_dataset, \n",
    "    batch_size=32, \n",
    "    shuffle=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training steps:  304\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                   | 0/304 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, step 0, loss 10.100526809692383\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|▏                                          | 1/304 [00:07<37:22,  7.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss:  2.2597110145970394\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|█▍                                        | 10/304 [00:13<03:51,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, step 10, loss 3.343229293823242\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|█▌                                        | 11/304 [00:20<13:22,  2.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss:  3.1884906166478206\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|██▊                                       | 20/304 [00:26<03:40,  1.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, step 20, loss 2.1369102001190186\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|██▉                                       | 21/304 [00:34<12:44,  2.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss:  2.270207254510177\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|████▏                                     | 30/304 [00:40<03:32,  1.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, step 30, loss 2.079723596572876\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|████▎                                     | 31/304 [00:47<12:03,  2.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss:  1.9885814064427425\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 13%|█████▌                                    | 40/304 [00:53<03:24,  1.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, step 40, loss 2.0545859336853027\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 13%|█████▋                                    | 41/304 [01:00<11:47,  2.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss:  2.1408801831697164\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|██████▉                                   | 50/304 [01:07<03:11,  1.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, step 50, loss 2.348806142807007\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|███████                                   | 51/304 [01:14<11:17,  2.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss:  2.4127080816971627\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|████████▎                                 | 60/304 [01:20<03:11,  1.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, step 60, loss 6.989198684692383\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|████████▍                                 | 61/304 [01:27<10:45,  2.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss:  7.351905421206825\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 23%|█████████▋                                | 70/304 [01:33<02:59,  1.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, step 70, loss 7.576042175292969\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 23%|█████████▊                                | 71/304 [01:40<10:23,  2.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss:  7.458835802580181\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 26%|███████████                               | 80/304 [01:46<02:54,  1.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, step 80, loss 6.392560958862305\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 27%|███████████▏                              | 81/304 [01:54<09:59,  2.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss:  6.215960452431126\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|████████████▍                             | 90/304 [02:00<02:46,  1.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, step 90, loss 5.413723945617676\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|████████████▌                             | 91/304 [02:07<09:32,  2.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss:  4.902527257015831\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|█████████████▍                           | 100/304 [02:13<02:38,  1.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, step 100, loss 4.339285850524902\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|█████████████▌                           | 101/304 [02:20<09:04,  2.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss:  3.9197933799342106\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 36%|██████████████▊                          | 110/304 [02:27<02:30,  1.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, step 110, loss 3.0781617164611816\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 37%|██████████████▉                          | 111/304 [02:34<08:38,  2.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss:  3.2137222290039062\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 39%|████████████████▏                        | 120/304 [02:40<02:22,  1.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, step 120, loss 3.3222146034240723\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████████████████▎                        | 121/304 [02:47<08:11,  2.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss:  2.878708287289268\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 43%|█████████████████▌                       | 130/304 [02:53<02:14,  1.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, step 130, loss 2.3282930850982666\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 43%|█████████████████▋                       | 131/304 [03:01<07:44,  2.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss:  2.5859820717259456\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 46%|██████████████████▉                      | 140/304 [03:07<02:07,  1.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, step 140, loss 2.4058308601379395\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 46%|███████████████████                      | 141/304 [03:14<07:19,  2.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss:  2.3473735608552633\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 49%|████████████████████▏                    | 150/304 [03:20<01:59,  1.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, step 150, loss 2.5113725662231445\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|████████████████████▎                    | 151/304 [03:27<06:51,  2.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss:  2.119058709395559\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 53%|█████████████████████▌                   | 160/304 [03:34<01:51,  1.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, step 160, loss 1.8075895309448242\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 53%|█████████████████████▋                   | 161/304 [03:41<06:23,  2.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss:  1.885526556717722\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 56%|██████████████████████▉                  | 170/304 [03:47<01:43,  1.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, step 170, loss 1.8050880432128906\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 56%|███████████████████████                  | 171/304 [03:54<05:57,  2.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss:  1.7780976546438116\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 59%|████████████████████████▎                | 180/304 [04:00<01:31,  1.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, step 180, loss 1.7527949810028076\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|████████████████████████▍                | 181/304 [04:07<05:26,  2.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss:  1.8345226488615338\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 62%|█████████████████████████▋               | 190/304 [04:14<01:28,  1.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, step 190, loss 1.7439758777618408\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 63%|█████████████████████████▊               | 191/304 [04:21<05:03,  2.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss:  1.8301861411646794\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 66%|██████████████████████████▉              | 200/304 [04:27<01:20,  1.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, step 200, loss 1.8739957809448242\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 66%|███████████████████████████              | 201/304 [04:34<04:36,  2.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss:  1.891387337132504\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 69%|████████████████████████████▎            | 210/304 [04:40<01:12,  1.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, step 210, loss 1.8245832920074463\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 69%|████████████████████████████▍            | 211/304 [04:48<04:09,  2.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss:  1.9575283652857731\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 72%|█████████████████████████████▋           | 220/304 [04:54<01:05,  1.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, step 220, loss 1.9632817506790161\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 73%|█████████████████████████████▊           | 221/304 [05:01<03:42,  2.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss:  1.9085243626644737\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 76%|███████████████████████████████          | 230/304 [05:07<00:55,  1.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, step 230, loss 1.7801181077957153\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 76%|███████████████████████████████▏         | 231/304 [05:14<03:14,  2.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss:  1.8545540257504112\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 79%|████████████████████████████████▎        | 240/304 [05:21<00:49,  1.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, step 240, loss 1.7608686685562134\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 79%|████████████████████████████████▌        | 241/304 [05:28<02:49,  2.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss:  1.8139666507118626\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 82%|█████████████████████████████████▋       | 250/304 [05:34<00:41,  1.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, step 250, loss 1.7355449199676514\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 83%|█████████████████████████████████▊       | 251/304 [05:41<02:22,  2.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss:  1.7578831722861843\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 86%|███████████████████████████████████      | 260/304 [05:47<00:34,  1.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, step 260, loss 1.7371573448181152\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 86%|███████████████████████████████████▏     | 261/304 [05:55<01:55,  2.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss:  1.7574412697239925\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 89%|████████████████████████████████████▍    | 270/304 [06:01<00:26,  1.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, step 270, loss 1.7176316976547241\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 89%|████████████████████████████████████▌    | 271/304 [06:08<01:28,  2.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss:  1.8040116962633634\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 92%|█████████████████████████████████████▊   | 280/304 [06:14<00:18,  1.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, step 280, loss 1.7642284631729126\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 92%|█████████████████████████████████████▉   | 281/304 [06:21<01:01,  2.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss:  1.771095075105366\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 95%|███████████████████████████████████████  | 290/304 [06:28<00:10,  1.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, step 290, loss 1.6263632774353027\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 96%|███████████████████████████████████████▏ | 291/304 [06:35<00:34,  2.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss:  1.7130958155581826\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 99%|████████████████████████████████████████▍| 300/304 [06:41<00:03,  1.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, step 300, loss 1.751288652420044\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 99%|████████████████████████████████████████▌| 301/304 [06:48<00:08,  2.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss:  1.7427982531095807\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 304/304 [06:50<00:00,  1.35s/it]\n",
      "  0%|                                                   | 0/304 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, step 0, loss 1.6347131729125977\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|▏                                          | 1/304 [00:07<36:36,  7.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss:  1.7390592474686473\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|█▍                                        | 10/304 [00:13<03:40,  1.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, step 10, loss 2.436089038848877\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|█▌                                        | 11/304 [00:20<13:20,  2.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss:  1.7454683404219777\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|██▊                                       | 20/304 [00:26<03:40,  1.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, step 20, loss 1.7400599718093872\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|██▉                                       | 21/304 [00:34<12:40,  2.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss:  1.7932132921720807\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|████▏                                     | 30/304 [00:40<03:32,  1.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, step 30, loss 1.599375605583191\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|████▎                                     | 31/304 [00:47<12:13,  2.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss:  1.7738842211271588\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 13%|█████▌                                    | 40/304 [00:53<03:23,  1.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, step 40, loss 1.6307644844055176\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 13%|█████▋                                    | 41/304 [01:00<11:45,  2.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss:  1.7542082134046053\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|██████▉                                   | 50/304 [01:06<03:16,  1.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, step 50, loss 1.594186782836914\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|███████                                   | 51/304 [01:14<11:19,  2.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss:  1.7149740520276522\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|████████▎                                 | 60/304 [01:20<03:08,  1.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, step 60, loss 1.6543705463409424\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|████████▍                                 | 61/304 [01:27<10:53,  2.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss:  1.7006404274388363\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 23%|█████████▋                                | 70/304 [01:33<03:01,  1.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, step 70, loss 1.6224242448806763\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 23%|█████████▊                                | 71/304 [01:40<10:25,  2.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss:  1.705836245888158\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 26%|███████████                               | 80/304 [01:47<02:53,  1.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, step 80, loss 2.1318023204803467\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 27%|███████████▏                              | 81/304 [01:54<09:58,  2.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss:  1.7470958107396175\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|████████████▍                             | 90/304 [02:00<02:44,  1.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, step 90, loss 1.6706109046936035\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|████████████▌                             | 91/304 [02:07<09:30,  2.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss:  1.715730165180407\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|█████████████▍                           | 100/304 [02:13<02:33,  1.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, step 100, loss 1.7353758811950684\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|█████████████▌                           | 101/304 [02:20<09:01,  2.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss:  1.718294244063528\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 36%|██████████████▊                          | 110/304 [02:27<02:29,  1.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, step 110, loss 1.7741936445236206\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 37%|██████████████▉                          | 111/304 [02:34<08:37,  2.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss:  1.7210934287623356\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 39%|████████████████▏                        | 120/304 [02:40<02:22,  1.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, step 120, loss 1.6137192249298096\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████████████████▎                        | 121/304 [02:47<08:10,  2.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss:  1.6881920663934005\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 43%|█████████████████▌                       | 130/304 [02:53<02:14,  1.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, step 130, loss 1.6025755405426025\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 43%|█████████████████▋                       | 131/304 [03:01<07:45,  2.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss:  1.6934186031943874\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 46%|██████████████████▉                      | 140/304 [03:07<02:05,  1.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, step 140, loss 1.7269644737243652\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 46%|███████████████████                      | 141/304 [03:14<07:16,  2.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss:  1.7586449070980674\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 49%|████████████████████▏                    | 150/304 [03:20<01:59,  1.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, step 150, loss 2.7020440101623535\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|████████████████████▎                    | 151/304 [03:27<06:50,  2.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss:  1.760340038098787\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 53%|█████████████████████▌                   | 160/304 [03:33<01:51,  1.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, step 160, loss 1.6397128105163574\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 53%|█████████████████████▋                   | 161/304 [03:40<06:23,  2.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss:  1.7200279235839844\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 56%|██████████████████████▉                  | 170/304 [03:47<01:43,  1.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, step 170, loss 2.3353705406188965\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 56%|███████████████████████                  | 171/304 [03:54<05:56,  2.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss:  1.7592909963507402\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 59%|████████████████████████▎                | 180/304 [04:00<01:35,  1.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, step 180, loss 2.438277006149292\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|████████████████████████▍                | 181/304 [04:07<05:30,  2.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss:  1.7341266431306537\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 62%|█████████████████████████▋               | 190/304 [04:13<01:27,  1.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, step 190, loss 1.5386656522750854\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 63%|█████████████████████████▊               | 191/304 [04:20<05:03,  2.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss:  1.7412777950889187\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 66%|██████████████████████████▉              | 200/304 [04:27<01:18,  1.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, step 200, loss 1.6495940685272217\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 66%|███████████████████████████              | 201/304 [04:34<04:35,  2.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss:  1.7104700991981907\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 69%|████████████████████████████▎            | 210/304 [04:40<01:12,  1.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, step 210, loss 2.0426104068756104\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 69%|████████████████████████████▍            | 211/304 [04:47<04:09,  2.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss:  1.734291478207237\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 72%|█████████████████████████████▋           | 220/304 [04:53<01:05,  1.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, step 220, loss 1.7599819898605347\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 73%|█████████████████████████████▊           | 221/304 [05:00<03:42,  2.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss:  1.7612208316200657\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 76%|███████████████████████████████          | 230/304 [05:07<00:57,  1.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, step 230, loss 1.946704387664795\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 76%|███████████████████████████████▏         | 231/304 [05:14<03:16,  2.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss:  1.7682836432206004\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 79%|████████████████████████████████▎        | 240/304 [05:20<00:49,  1.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, step 240, loss 1.6938929557800293\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 79%|████████████████████████████████▌        | 241/304 [05:27<02:49,  2.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss:  1.7179912767912213\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 82%|█████████████████████████████████▋       | 250/304 [05:33<00:41,  1.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, step 250, loss 1.7154712677001953\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 83%|█████████████████████████████████▊       | 251/304 [05:41<02:22,  2.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss:  1.7699468512284129\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 86%|███████████████████████████████████      | 260/304 [05:47<00:34,  1.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, step 260, loss 2.214583396911621\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 86%|███████████████████████████████████▏     | 261/304 [05:54<01:55,  2.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss:  1.7680870859246505\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 89%|████████████████████████████████████▍    | 270/304 [06:00<00:26,  1.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, step 270, loss 1.6430859565734863\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 89%|████████████████████████████████████▌    | 271/304 [06:07<01:28,  2.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss:  1.7186010260331004\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 92%|█████████████████████████████████████▊   | 280/304 [06:14<00:18,  1.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, step 280, loss 1.6063998937606812\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 92%|█████████████████████████████████████▉   | 281/304 [06:21<01:01,  2.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss:  1.7059330187345807\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 95%|███████████████████████████████████████  | 290/304 [06:27<00:10,  1.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, step 290, loss 1.665834903717041\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 96%|███████████████████████████████████████▏ | 291/304 [06:34<00:34,  2.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss:  1.7257891203227795\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 99%|████████████████████████████████████████▍| 300/304 [06:40<00:03,  1.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, step 300, loss 1.8212969303131104\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 99%|████████████████████████████████████████▌| 301/304 [06:48<00:08,  2.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss:  1.7344785991467928\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 304/304 [06:50<00:00,  1.35s/it]\n"
     ]
    }
   ],
   "source": [
    "# 4. run the training of the model\n",
    "# Hint: for implementing the forward pass and loss computation, carefully look at the exercise sheets \n",
    "# and the links to examples in HF tutorials.\n",
    "\n",
    "# put the model in training mode\n",
    "model.train()\n",
    "# move the model to the device (e.g. GPU)\n",
    "model = model.to(device)\n",
    "\n",
    "# trianing configutations \n",
    "# feel free to play around with these\n",
    "epochs = 2\n",
    "train_steps =  len(train_dataset) // 32\n",
    "print(\"Number of training steps: \", train_steps)\n",
    "# number of test steps to perform every 10 training steps\n",
    "# (smaller that the entore test split for reasons of comp. time)\n",
    "num_test_steps = len(test_dataset) // 32 # 5\n",
    "\n",
    "# define optimizer and learning rate\n",
    "optimizer = torch.optim.AdamW(model.parameters(),\n",
    "                              lr=2e-4,\n",
    "                              # lr=5e-4  # given\n",
    "                             )\n",
    "\n",
    "# define the loss function\n",
    "loss_function = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "# define some variables to accumulate the losses\n",
    "losses = []\n",
    "test_losses = []\n",
    "\n",
    "# iterate over epochs\n",
    "for e in range(epochs):\n",
    "    # iterate over training steps\n",
    "    for i in tqdm(range(train_steps)):\n",
    "        # get a batch of data\n",
    "        x = next(iter(dataloader))\n",
    "        # move the data to the device (GPU)\n",
    "        x = x.to(device)\n",
    "        \n",
    "        # forward pass through the model\n",
    "        x['input_ids'] = x['input_ids'].squeeze(1)\n",
    "        x['attention_mask'] = x['attention_mask'].squeeze(1)\n",
    "        outputs = model(\n",
    "            **x\n",
    "        )\n",
    "        # get the loss\n",
    "        logits = outputs.logits\n",
    "        targets = x['input_ids']\n",
    "        # print(logits.shape, targets.shape)\n",
    "        B, T, C = logits.shape\n",
    "        # use next token prediction loss with proper shifting of tokens\n",
    "        # just predict the answer key token as for finetuning, no need to focus on other tokens\n",
    "        # answer key token is the last one (as inspected in the batch), so use that as the target\n",
    "        loss = loss_function(logits[:, -2, :], targets[:, -1])\n",
    "\n",
    "        # this line calculates loss at each position in the sequence which is not necessary, we just need to predict answer key\n",
    "        # loss = loss_function(logits[..., :-1, :].contiguous().view(B*(T-1), C),\n",
    "        #                      targets[..., 1:].contiguous().view(B*(T-1))\n",
    "        #                     )\n",
    "        \n",
    "        # backward pass\n",
    "        loss.backward()\n",
    "        losses.append(loss.item())\n",
    "        \n",
    "        # update the parameters of the model\n",
    "        optimizer.step()\n",
    "\n",
    "        # zero out gradient for next step\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # evaluate on test set every 10 steps\n",
    "        if i % 10 == 0:\n",
    "            print(f\"Epoch {e}, step {i}, loss {loss.item()}\")\n",
    "            # track test loss for the evaluation iteration\n",
    "            test_loss = 0\n",
    "            for j in range(num_test_steps):\n",
    "                # get test batch\n",
    "                x_test = next(iter(test_dataloader))\n",
    "                x_test = x_test.to(device)\n",
    "                x_test['input_ids'] = x_test['input_ids'].squeeze(1)\n",
    "                x_test['attention_mask'] = x_test['attention_mask'].squeeze(1)\n",
    "                with torch.no_grad():\n",
    "                    test_outputs = model(\n",
    "                        **x_test\n",
    "                    )\n",
    "                    logits = test_outputs.logits\n",
    "                test_loss += loss_function(logits[:, -2, :], x_test['input_ids'][:, -1])\n",
    "            test_losses.append(test_loss.item() / num_test_steps)\n",
    "            print(\"Test loss: \", test_loss.item() / num_test_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 5. Plot the fine-tuning loss and MAKE SURE TO SAVE IT AND SUBMIT IT\n",
    "# plot training losses on x axis\n",
    "# fig = plt.figure()\n",
    "fig=plt.figure(figsize=(8,6))\n",
    "plt.plot(losses,label='train loss')### YOUR CODE HERE ####)\n",
    "plt.plot(np.arange(0,len(test_losses * 10), 10), test_losses, label='validation loss')\n",
    "plt.xlabel(\"Training steps\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "fig.savefig(f'loss_commonsenseqa_gpt2_1505.png', dpi=fig.dpi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('A revolving door is convenient for two direction travel, but it also serves as a security measure at a what? A. bank B. library C. department store D. mall E. new york\\nAnswer: ',\n",
       " 'A')"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# print a few predictions on the eval dataset to see what the model predicts\n",
    "\n",
    "# construct a list of questions without the ground truth label\n",
    "# and compare prediction of the model with the ground truth\n",
    "\n",
    "def construct_test_samples(example):\n",
    "    \"\"\"\n",
    "    Helper for converting input examples which have \n",
    "    a separate qquestion, labels, answer options\n",
    "    into a single string for testing the model.\n",
    "\n",
    "    Arguments\n",
    "    ---------\n",
    "    example: dict\n",
    "        Sample input from the dataset which contains the \n",
    "        question, answer labels (e.g. A, B, C, D),\n",
    "        the answer options for the question, and which \n",
    "        of the answers is correct.\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    input_text: str, str\n",
    "        Tuple: Formatted test text which contains the question,\n",
    "        the forwatted answer options (e.g., 'A. <option 1> B. <option 2>' etc); \n",
    "        the ground truth answer label only.\n",
    "    \"\"\"\n",
    "\n",
    "    answer_options_list = list(zip(\n",
    "        example[\"choices\"][\"label\"],\n",
    "        example[\"choices\"][\"text\"]\n",
    "    ))\n",
    "    # join each label and text with . and space\n",
    "    answer_options = ['. '.join(y) for y in answer_options_list] ### YOUR CODE HERE ####\n",
    "    # join the list of options with spaces into single string\n",
    "    answer_options_string = ' '.join(answer_options) ### YOUR CODE HERE ####\n",
    "    # combine question and answer options\n",
    "    input_text = example[\"question\"] + \" \" + answer_options_string\n",
    "    # create the test input text which should be:\n",
    "    # the input text, followed by the string \"Answer: \"\n",
    "    # we don't need to append the ground truth answer since we are creating test inputs\n",
    "    # and the answer should be predicted.\n",
    "    input_text += \"\\nAnswer: \" ### YOUR CODE HERE ####\n",
    "\n",
    "    return input_text, example[\"answerKey\"]\n",
    "\n",
    "test_samples = [construct_test_samples(dataset[\"validation\"][i]) for i in range(10)]\n",
    "test_samples[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_samples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## inspect predictions after finetuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input text + model's prediction:\n",
      " A revolving door is convenient for two direction travel, but it also serves as a security measure at a what? A. bank B. library C. department store D. mall E. new york\n",
      "Answer:  A\n",
      "---\n",
      "Correct answer: A\n",
      "\n",
      "\n",
      "Input text + model's prediction:\n",
      " What do people aim to do at work? A. complete job B. learn from each other C. kill animals D. wear hats E. talk to each other\n",
      "Answer:  A\n",
      "---\n",
      "Correct answer: A\n",
      "\n",
      "\n",
      "Input text + model's prediction:\n",
      " Where would you find magazines along side many other printed works? A. doctor B. bookstore C. market D. train station E. mortuary\n",
      "Answer:  A\n",
      "---\n",
      "Correct answer: B\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input text + model's prediction:\n",
      " Where are  you likely to find a hamburger? A. fast food restaurant B. pizza C. ground up dead cows D. mouth E. cow carcus\n",
      "Answer:  A\n",
      "---\n",
      "Correct answer: A\n",
      "\n",
      "\n",
      "Input text + model's prediction:\n",
      " James was looking for a good place to buy farmland.  Where might he look? A. midwest B. countryside C. estate D. farming areas E. illinois\n",
      "Answer:  C\n",
      "---\n",
      "Correct answer: A\n",
      "\n",
      "\n",
      "Input text + model's prediction:\n",
      " What island country is ferret popular? A. own home B. north carolina C. great britain D. hutch E. outdoors\n",
      "Answer:  B\n",
      "---\n",
      "Correct answer: C\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input text + model's prediction:\n",
      " In what Spanish speaking North American country can you get a great cup of coffee? A. mildred's coffee shop B. mexico C. diner D. kitchen E. canteen\n",
      "Answer:  C\n",
      "---\n",
      "Correct answer: B\n",
      "\n",
      "\n",
      "Input text + model's prediction:\n",
      " What do animals do when an enemy is approaching? A. feel pleasure B. procreate C. pass water D. listen to each other E. sing\n",
      "Answer:  E\n",
      "---\n",
      "Correct answer: D\n",
      "\n",
      "\n",
      "Input text + model's prediction:\n",
      " Reading newspaper one of many ways to practice your what? A. literacy B. knowing how to read C. money D. buying E. money bank\n",
      "Answer:  C\n",
      "---\n",
      "Correct answer: A\n",
      "\n",
      "\n",
      "Input text + model's prediction:\n",
      " What do people typically do while playing guitar? A. cry B. hear sounds C. singing D. arthritis E. making music\n",
      "Answer:  A\n",
      "---\n",
      "Correct answer: C\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Test the model\n",
    "# set it to evaluation mode\n",
    "model.eval()\n",
    "\n",
    "predictions = []\n",
    "for sample in test_samples:\n",
    "    input_text = sample[0]\n",
    "    input_ids = tokenizer(input_text, return_tensors=\"pt\").to(device)\n",
    "    output = model.generate(\n",
    "        input_ids.input_ids,\n",
    "        attention_mask = input_ids.attention_mask,\n",
    "        max_new_tokens=1,  # originally it was 2\n",
    "        do_sample=True,\n",
    "        temperature=0.4,\n",
    "    )\n",
    "    prediction = tokenizer.decode(output[0], skip_special_tokens=True)\n",
    "    print(f\"Input text + model's prediction:\\n {prediction}\\n---\")\n",
    "    print(f\"Correct answer: {sample[1]}\\n\\n\")\n",
    "    predictions.append((input_text, prediction, sample[1]))\n",
    "\n",
    "# print(\"Predictions of trained model \", predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## inspect predictions before any finetuning on this dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A revolving door is convenient for two direction travel, but it also serves as a security measure at a what? A. bank B. library C. department store D. mall E. new york\n",
      "Answer:  The \n",
      "---\n",
      "What do people aim to do at work? A. complete job B. learn from each other C. kill animals D. wear hats E. talk to each other\n",
      "Answer:  If \n",
      "---\n",
      "Where would you find magazines along side many other printed works? A. doctor B. bookstore C. market D. train station E. mortuary\n",
      "Answer:  I \n",
      "---\n",
      "Where are  you likely to find a hamburger? A. fast food restaurant B. pizza C. ground up dead cows D. mouth E. cow carcus\n",
      "Answer:  I \n",
      "---\n",
      "James was looking for a good place to buy farmland.  Where might he look? A. midwest B. countryside C. estate D. farming areas E. illinois\n",
      "Answer:  The \n",
      "---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "What island country is ferret popular? A. own home B. north carolina C. great britain D. hutch E. outdoors\n",
      "Answer:  The \n",
      "---\n",
      "In what Spanish speaking North American country can you get a great cup of coffee? A. mildred's coffee shop B. mexico C. diner D. kitchen E. canteen\n",
      "Answer:  I \n",
      "---\n",
      "What do animals do when an enemy is approaching? A. feel pleasure B. procreate C. pass water D. listen to each other E. sing\n",
      "Answer:  What \n",
      "---\n",
      "Reading newspaper one of many ways to practice your what? A. literacy B. knowing how to read C. money D. buying E. money bank\n",
      "Answer:  You \n",
      "---\n",
      "What do people typically do while playing guitar? A. cry B. hear sounds C. singing D. arthritis E. making music\n",
      "Answer:  They \n",
      "---\n"
     ]
    }
   ],
   "source": [
    "# Test the model \n",
    "\n",
    "org_model = GPT2LMHeadModel.from_pretrained(\"gpt2\").to(device) ### YOUR CODE HERE ####\n",
    "# set it to evaluation mode\n",
    "org_model.eval()\n",
    "\n",
    "predictions = []\n",
    "for sample in test_samples:\n",
    "    input_text = sample[0]\n",
    "    input_ids = tokenizer(input_text, return_tensors=\"pt\").to(device)\n",
    "    output = org_model.generate(\n",
    "        input_ids.input_ids,\n",
    "        attention_mask = input_ids.attention_mask,\n",
    "        max_new_tokens=2,\n",
    "        do_sample=True,\n",
    "        temperature=0.4,\n",
    "    )\n",
    "    prediction = tokenizer.decode(output[0], skip_special_tokens=True)\n",
    "    print(prediction, '\\n---')\n",
    "    predictions.append((input_text, prediction, sample[1]))\n",
    "\n",
    "# print(\"Predictions of trained model \", predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Accuracy computation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len train = 9741, len val = 1221\n"
     ]
    }
   ],
   "source": [
    "all_test_samples = [construct_test_samples(dataset[\"validation\"][i]) for i in range(len(dataset[\"validation\"]))]\n",
    "all_train_samples = [construct_test_samples(dataset[\"train\"][i]) for i in range(len(dataset[\"train\"]))]\n",
    "print(f'len train = {len(all_train_samples)}, len val = {len(all_test_samples)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_accuracy(list_of_samples, model):\n",
    "    model.eval()\n",
    "\n",
    "    correct = 0\n",
    "    for sample in test_samples:\n",
    "        input_text = sample[0]\n",
    "        input_ids = tokenizer(input_text, return_tensors=\"pt\").to(device)\n",
    "        output = model.generate(\n",
    "            input_ids.input_ids,\n",
    "            attention_mask = input_ids.attention_mask,\n",
    "            max_new_tokens=1,\n",
    "            do_sample=True,\n",
    "            temperature=0.4,\n",
    "        )\n",
    "        prediction = tokenizer.decode(output[0], skip_special_tokens=True)\n",
    "        # print(prediction, '\\n---')\n",
    "        # print(prediction[len(input_text):].strip())\n",
    "        predicted_answer_key = prediction[len(input_text):].strip()\n",
    "        true_answer_key = sample[1]\n",
    "        if predicted_answer_key == true_answer_key:\n",
    "            correct += 1\n",
    "\n",
    "\n",
    "    return correct, len(list_of_samples), correct/len(list_of_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "((0, 1221, 0.0), (0, 9741, 0.0))"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compute_accuracy(all_test_samples, org_model), compute_accuracy(all_train_samples, org_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "((4, 1221, 0.003276003276003276), (2, 9741, 0.0002053177291859152))"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compute_accuracy(all_test_samples, model), compute_accuracy(all_train_samples, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Questions:\n",
    "> 1. Provide a brief description of the CommonsenseQA dataset. What kind of task was it developed for, what do the single columns contain?\n",
    "\n",
    "CommonsenseQA dataset was developed to assess the performance of language models in question-answering tasks that require some form of prior knowledge or world knowledge that humans find _straightforward_ (hence \"commonsense\"). It contains multiple choice answer type questions with only single correct answer and these questions are supposedly easy to answer for humans without any associated context (e.g., long paragraphs or passages).\n",
    "\n",
    "The dataset has 5 columns:\n",
    "\n",
    " - id: a unique identifier for each question\n",
    " - question: actual text for the question\n",
    " - question_concept: the background of the question, some real world idea or concept\n",
    " - choices: contains `label`s (A, B, C or D) and their corresponding response `text`s in a dictionary\n",
    " - answerKey: the groundtruth answer key (one of A, B, C or D)\n",
    "\n",
    "---\n",
    "\n",
    "> 2. What loss function is computed for this training? Provide the name of the function (conceptual, not necessarily the name of a function in the code).\n",
    "\n",
    "The **cross-entropy loss** function is computed for this training. It is computed using the computed distribution over the next token (a vector having positive values of size $V$, summing to 1), and the actual next token (a one-hot vector of size $V$ with 1 at the index of the next token).\n",
    "\n",
    "---\n",
    "\n",
    "> 3. Given your loss curve, do you think your model will perform well on answering common sense questions? (Note: there is no single right answer; you need to interpret your specific plot)\n",
    "\n",
    "From the loss plot, we can see that both training and validation losses seem to have converged to a loss below $2$, although there are small irregularities. I have also increased the no. of epochs (to 2), but the loss did not decrease further. Even though the loss has converged, upon inspection of predictions, we see that the model is still predicting wrong answers for most of the questions.\n",
    "\n",
    "\n",
    "---\n",
    "> 4. Inspect the predictions above. On how many test questions did the model predict the right answer? Compute the accuracy.\n",
    "\n",
    "Observations from above cells:\n",
    "- Before finetuning, `org_model` was generating tokens like: \"The\", \"If\", \"I\", \"You\" etc. that do not correspond to the answer keys. This may be because model was trying to answer the question in a full sentence, or it is likely generating tokens that are most likely to begin a sentence.\n",
    "- After the finetuning, I observe that the `model` is indeed predicting tokens corresponding to the answer keys, so there is definitely some improvement of finetuning on this particular dataset. However, almost all of the answers predicted by the model is wrong so it is still a bad model in doing the task that it was finetuned to do.\n",
    "- The accuracy over all training/test samples is very low, For the original (not finetuned) model, it is $0$. For the finetuned model, the model got only 4 correct out of 1221 samples. Interestingly it also got most of the training samples wrong, despite the converged loss value on the training set!\n",
    "\n",
    "\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
